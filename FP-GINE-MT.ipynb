{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed60b7e1-ce9e-4fca-8fa2-b8901900f1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "PolyGNN Atom feature dimension: 80\n",
      "PolyGNN Bond feature dimension: 6\n",
      "MixFP fingerprint dimension: 1048\n",
      "Loading data...\n",
      "Data loaded and cleaned, shape: (16420, 3)\n",
      "Detected target properties: ['SP', 'Tc', 'Td', 'Tg', 'Tm']\n",
      "Number of tasks (properties): 5\n",
      "\n",
      "Pre-generating PyG Data objects for unique SMILES...\n",
      "Pre-generated data not found. Generating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ge\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated data for 10755 unique SMILES.\n",
      "Saving pre-generated data to ./best_models_gine_mixfp_multitask_v3\\pregenerated_data.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 10:31:31,100] A new study created in memory with name: no-name-6f9dfebf-911b-42a7-8789-fb3d683a0397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered dataframe based on successful data generation, shape: (16420, 3)\n",
      "\n",
      "Splitting data (stratified by property)...\n",
      "Train/Val set size: 13136, Test set size: 3284\n",
      "Train/Val property distribution:\n",
      " prop\n",
      "SP    0.042707\n",
      "Tc    0.026035\n",
      "Td    0.311663\n",
      "Tg    0.442296\n",
      "Tm    0.177299\n",
      "Name: proportion, dtype: float64\n",
      "Test property distribution:\n",
      " prop\n",
      "SP    0.042935\n",
      "Tc    0.025883\n",
      "Td    0.311815\n",
      "Tg    0.442144\n",
      "Tm    0.177223\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Fitting main scalers (MinMaxScaler) per property...\n",
      "Main scalers and target columns saved to: ./best_models_gine_mixfp_multitask_v3\\multitask_minmax_scalers.joblib, ./best_models_gine_mixfp_multitask_v3\\target_cols_multitask.joblib\n",
      "\n",
      "--- Starting 5-Fold Stratified CV ---\n",
      "\n",
      "===== Fold 1/5 =====\n",
      "Fold Train size: 10508, Fold Val size: 2628\n",
      "\n",
      "--- Fold 1: Fitting fold scalers per property ---\n",
      "Fold Train size after dropping unscalable samples: 10508\n",
      "Fold Val size after dropping unscalable samples: 2628\n",
      "\n",
      "--- Fold 1: Running Optuna ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 10:33:13,273] Trial 0 finished with value: 0.017327703500111594 and parameters: {'lr': 4.3764485735513555e-05, 'weight_decay': 7.809930704286869e-06, 'dropout': 0.4084202758591543, 'batch_size': 128, 'fusion_hidden_dim': 512, 'gnn_hidden_dim': 32, 'gnn_layers': 2, 'fp_hidden_dim': 512, 'fp_layers': 3, 'interaction_hidden_dim': 64}. Best is trial 0 with value: 0.017327703500111594.\n",
      "[I 2025-05-12 10:37:35,307] Trial 1 finished with value: 0.0068787906051291725 and parameters: {'lr': 0.0004228989678120472, 'weight_decay': 5.763601079050454e-06, 'dropout': 0.30211311728566836, 'batch_size': 128, 'fusion_hidden_dim': 256, 'gnn_hidden_dim': 32, 'gnn_layers': 3, 'fp_hidden_dim': 256, 'fp_layers': 4, 'interaction_hidden_dim': 32}. Best is trial 1 with value: 0.0068787906051291725.\n",
      "[I 2025-05-12 10:42:16,493] Trial 2 finished with value: 0.00701896073677702 and parameters: {'lr': 0.00036531980776648355, 'weight_decay': 1.5525776127379146e-06, 'dropout': 0.34974794485206195, 'batch_size': 128, 'fusion_hidden_dim': 128, 'gnn_hidden_dim': 128, 'gnn_layers': 2, 'fp_hidden_dim': 512, 'fp_layers': 1, 'interaction_hidden_dim': 128}. Best is trial 1 with value: 0.0068787906051291725.\n",
      "[I 2025-05-12 10:47:18,789] Trial 3 finished with value: 0.006079674822470611 and parameters: {'lr': 0.0007234553291987466, 'weight_decay': 1.601030883164217e-05, 'dropout': 0.31607557858425817, 'batch_size': 128, 'fusion_hidden_dim': 128, 'gnn_hidden_dim': 32, 'gnn_layers': 5, 'fp_hidden_dim': 128, 'fp_layers': 1, 'interaction_hidden_dim': 64}. Best is trial 3 with value: 0.006079674822470611.\n",
      "[I 2025-05-12 10:51:48,375] Trial 4 finished with value: 0.013820025713655293 and parameters: {'lr': 3.677961070486078e-05, 'weight_decay': 5.6055372748121375e-05, 'dropout': 0.19680577646522304, 'batch_size': 64, 'fusion_hidden_dim': 64, 'gnn_hidden_dim': 256, 'gnn_layers': 2, 'fp_hidden_dim': 256, 'fp_layers': 3, 'interaction_hidden_dim': 64}. Best is trial 3 with value: 0.006079674822470611.\n",
      "[I 2025-05-12 10:51:54,365] Trial 5 pruned. \n",
      "[I 2025-05-12 10:51:56,740] Trial 6 pruned. \n",
      "[I 2025-05-12 10:52:00,091] Trial 7 pruned. \n",
      "[I 2025-05-12 10:52:05,762] Trial 8 pruned. \n",
      "[I 2025-05-12 10:53:41,146] Trial 9 pruned. \n",
      "[I 2025-05-12 10:53:46,178] Trial 10 pruned. \n",
      "[I 2025-05-12 10:57:36,630] Trial 11 finished with value: 0.005548579509783852 and parameters: {'lr': 0.0009071545527786609, 'weight_decay': 5.5222020546221816e-06, 'dropout': 0.22396212902289414, 'batch_size': 128, 'fusion_hidden_dim': 256, 'gnn_hidden_dim': 32, 'gnn_layers': 4, 'fp_hidden_dim': 256, 'fp_layers': 4, 'interaction_hidden_dim': 32}. Best is trial 11 with value: 0.005548579509783852.\n",
      "[I 2025-05-12 11:01:00,765] Trial 12 finished with value: 0.005831561772397353 and parameters: {'lr': 0.0009714890205239404, 'weight_decay': 3.5121712099323737e-06, 'dropout': 0.22372728102297615, 'batch_size': 128, 'fusion_hidden_dim': 256, 'gnn_hidden_dim': 32, 'gnn_layers': 4, 'fp_hidden_dim': 256, 'fp_layers': 4, 'interaction_hidden_dim': 32}. Best is trial 11 with value: 0.005548579509783852.\n",
      "[I 2025-05-12 11:01:02,702] Trial 13 pruned. \n",
      "[I 2025-05-12 11:01:05,022] Trial 14 pruned. \n",
      "[I 2025-05-12 11:04:47,857] Trial 15 finished with value: 0.00573714448428836 and parameters: {'lr': 0.0005020897006190884, 'weight_decay': 3.5616555597542553e-06, 'dropout': 0.12730862667194673, 'batch_size': 128, 'fusion_hidden_dim': 256, 'gnn_hidden_dim': 32, 'gnn_layers': 4, 'fp_hidden_dim': 256, 'fp_layers': 4, 'interaction_hidden_dim': 32}. Best is trial 11 with value: 0.005548579509783852.\n",
      "[I 2025-05-12 11:04:52,416] Trial 16 pruned. \n",
      "[I 2025-05-12 11:06:25,123] Trial 17 pruned. \n",
      "[I 2025-05-12 11:06:31,305] Trial 18 pruned. \n",
      "[I 2025-05-12 11:06:36,330] Trial 19 pruned. \n",
      "[I 2025-05-12 11:06:37,845] Trial 20 pruned. \n",
      "[I 2025-05-12 11:10:21,692] Trial 21 finished with value: 0.005347769901060723 and parameters: {'lr': 0.0009733776929225491, 'weight_decay': 4.230581572624207e-06, 'dropout': 0.15422077302580298, 'batch_size': 128, 'fusion_hidden_dim': 256, 'gnn_hidden_dim': 32, 'gnn_layers': 4, 'fp_hidden_dim': 256, 'fp_layers': 4, 'interaction_hidden_dim': 32}. Best is trial 21 with value: 0.005347769901060723.\n",
      "[I 2025-05-12 11:10:23,596] Trial 22 pruned. \n",
      "[I 2025-05-12 11:10:32,944] Trial 23 pruned. \n",
      "[I 2025-05-12 11:10:37,069] Trial 24 pruned. \n",
      "[I 2025-05-12 11:10:38,993] Trial 25 pruned. \n",
      "[I 2025-05-12 11:10:42,295] Trial 26 pruned. \n",
      "[I 2025-05-12 11:10:44,405] Trial 27 pruned. \n",
      "[I 2025-05-12 11:18:08,981] Trial 28 finished with value: 0.005703810209427897 and parameters: {'lr': 0.0004055579632308798, 'weight_decay': 6.563200418161354e-06, 'dropout': 0.13535089975766337, 'batch_size': 64, 'fusion_hidden_dim': 64, 'gnn_hidden_dim': 128, 'gnn_layers': 5, 'fp_hidden_dim': 1024, 'fp_layers': 4, 'interaction_hidden_dim': 128}. Best is trial 21 with value: 0.005347769901060723.\n",
      "[I 2025-05-12 11:18:13,314] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Optuna finished. Duration: 2802.22 sec\n",
      "Fold 1: Optuna best hyperparameters:\n",
      " {'lr': 0.0009733776929225491, 'weight_decay': 4.230581572624207e-06, 'dropout': 0.15422077302580298, 'batch_size': 128, 'fusion_hidden_dim': 256, 'gnn_hidden_dim': 32, 'gnn_layers': 4, 'fp_hidden_dim': 256, 'fp_layers': 4, 'interaction_hidden_dim': 32}\n",
      "Fold 1: Best validation loss (Average MSE scaled): 0.005348\n",
      "\n",
      "--- Fold 1: Training final model ---\n",
      " F1 E010/250 | Tr L(S): 0.01063 | V L(S): 0.01083 | V SP MAE: 51.3563\n",
      " F1 E020/250 | Tr L(S): 0.00723 | V L(S): 0.00701 | V SP MAE: 40.6567\n",
      " F1 E030/250 | Tr L(S): 0.00583 | V L(S): 0.00677 | V SP MAE: 40.5349\n",
      " F1 E040/250 | Tr L(S): 0.00504 | V L(S): 0.00562 | V SP MAE: 36.9266\n",
      " F1 E050/250 | Tr L(S): 0.00470 | V L(S): 0.00620 | V SP MAE: 38.1552\n",
      " F1 E060/250 | Tr L(S): 0.00412 | V L(S): 0.00546 | V SP MAE: 37.5301\n",
      " F1 E070/250 | Tr L(S): 0.00394 | V L(S): 0.00627 | V SP MAE: 36.5227\n",
      " F1 E080/250 | Tr L(S): 0.00434 | V L(S): 0.00559 | V SP MAE: 35.3901\n",
      " F1 E090/250 | Tr L(S): 0.00283 | V L(S): 0.00511 | V SP MAE: 33.6113\n",
      " F1 E100/250 | Tr L(S): 0.00254 | V L(S): 0.00483 | V SP MAE: 33.1859\n",
      " F1 E110/250 | Tr L(S): 0.00261 | V L(S): 0.00503 | V SP MAE: 33.4996\n",
      " F1 E120/250 | Tr L(S): 0.00219 | V L(S): 0.00468 | V SP MAE: 32.2482\n",
      " F1 E130/250 | Tr L(S): 0.00190 | V L(S): 0.00454 | V SP MAE: 32.1789\n",
      " F1 E140/250 | Tr L(S): 0.00199 | V L(S): 0.00462 | V SP MAE: 31.6427\n",
      " F1 E150/250 | Tr L(S): 0.00166 | V L(S): 0.00426 | V SP MAE: 32.2045\n",
      " F1 E160/250 | Tr L(S): 0.00160 | V L(S): 0.00434 | V SP MAE: 30.9025\n",
      " F1 E170/250 | Tr L(S): 0.00153 | V L(S): 0.00429 | V SP MAE: 31.0801\n",
      " F1 E180/250 | Tr L(S): 0.00147 | V L(S): 0.00430 | V SP MAE: 31.0282\n",
      " F1 E190/250 | Tr L(S): 0.00139 | V L(S): 0.00427 | V SP MAE: 31.3567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 11:26:51,039] A new study created in memory with name: no-name-19511b5b-294c-4c07-a352-e2fccb032d75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " F1 E191/250 | Tr L(S): 0.00145 | V L(S): 0.00420 | V SP MAE: 30.5450\n",
      "  Early stopping. Best Epoch: 161\n",
      "  Fold 1 training finished. Duration: 517.56 sec.\n",
      "  Fold 1 best model saved to: ./best_models_gine_mixfp_multitask_v3\\model_fold_1_best.pth (from epoch 161)\n",
      "\n",
      "===== Fold 2/5 =====\n",
      "Fold Train size: 10509, Fold Val size: 2627\n",
      "\n",
      "--- Fold 2: Fitting fold scalers per property ---\n",
      "Fold Train size after dropping unscalable samples: 10509\n",
      "Fold Val size after dropping unscalable samples: 2627\n",
      "\n",
      "--- Fold 2: Running Optuna ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 11:33:48,306] Trial 0 finished with value: 0.01763689745976089 and parameters: {'lr': 2.6026002493402733e-05, 'weight_decay': 1.4459507379353897e-05, 'dropout': 0.38997659152464814, 'batch_size': 128, 'fusion_hidden_dim': 256, 'gnn_hidden_dim': 256, 'gnn_layers': 4, 'fp_hidden_dim': 256, 'fp_layers': 1, 'interaction_hidden_dim': 128}. Best is trial 0 with value: 0.01763689745976089.\n",
      "[I 2025-05-12 11:36:27,766] Trial 1 finished with value: 0.023089348362469876 and parameters: {'lr': 2.5824444261579055e-05, 'weight_decay': 7.389741765055624e-05, 'dropout': 0.4500882884233117, 'batch_size': 64, 'fusion_hidden_dim': 128, 'gnn_hidden_dim': 32, 'gnn_layers': 3, 'fp_hidden_dim': 1024, 'fp_layers': 2, 'interaction_hidden_dim': 32}. Best is trial 0 with value: 0.01763689745976089.\n",
      "[I 2025-05-12 11:41:06,828] Trial 2 finished with value: 0.005692866564170944 and parameters: {'lr': 0.0004351188867563945, 'weight_decay': 2.999758373587731e-06, 'dropout': 0.2771296810111603, 'batch_size': 128, 'fusion_hidden_dim': 512, 'gnn_hidden_dim': 64, 'gnn_layers': 5, 'fp_hidden_dim': 1024, 'fp_layers': 2, 'interaction_hidden_dim': 32}. Best is trial 2 with value: 0.005692866564170944.\n",
      "[I 2025-05-12 11:53:20,732] Trial 3 finished with value: 0.006005943316849326 and parameters: {'lr': 6.630418187736115e-05, 'weight_decay': 3.6384153868498796e-05, 'dropout': 0.14506516288769555, 'batch_size': 32, 'fusion_hidden_dim': 128, 'gnn_hidden_dim': 128, 'gnn_layers': 4, 'fp_hidden_dim': 1024, 'fp_layers': 4, 'interaction_hidden_dim': 64}. Best is trial 2 with value: 0.005692866564170944.\n",
      "[I 2025-05-12 12:01:34,465] Trial 4 finished with value: 0.02169337628549275 and parameters: {'lr': 1.718103721732428e-05, 'weight_decay': 6.49405152110118e-06, 'dropout': 0.4014549108079517, 'batch_size': 64, 'fusion_hidden_dim': 64, 'gnn_hidden_dim': 256, 'gnn_layers': 5, 'fp_hidden_dim': 512, 'fp_layers': 1, 'interaction_hidden_dim': 128}. Best is trial 2 with value: 0.005692866564170944.\n",
      "[I 2025-05-12 12:01:36,601] Trial 5 pruned. \n",
      "[I 2025-05-12 12:03:04,510] Trial 6 finished with value: 0.020219072889178624 and parameters: {'lr': 2.0795505674950907e-05, 'weight_decay': 2.3751869092661326e-05, 'dropout': 0.31111811349739404, 'batch_size': 32, 'fusion_hidden_dim': 256, 'gnn_hidden_dim': 64, 'gnn_layers': 1, 'fp_hidden_dim': 256, 'fp_layers': 2, 'interaction_hidden_dim': 64}. Best is trial 2 with value: 0.005692866564170944.\n",
      "[I 2025-05-12 12:08:51,019] Trial 7 pruned. \n",
      "[I 2025-05-12 12:09:26,275] Trial 8 finished with value: 0.019117300384469706 and parameters: {'lr': 4.2466543942425454e-05, 'weight_decay': 3.189784574429448e-06, 'dropout': 0.4529861828553282, 'batch_size': 128, 'fusion_hidden_dim': 512, 'gnn_hidden_dim': 128, 'gnn_layers': 1, 'fp_hidden_dim': 512, 'fp_layers': 3, 'interaction_hidden_dim': 128}. Best is trial 2 with value: 0.005692866564170944.\n",
      "[I 2025-05-12 12:09:38,475] Trial 9 pruned. \n",
      "[I 2025-05-12 12:12:48,938] Trial 10 pruned. \n",
      "[I 2025-05-12 12:12:54,688] Trial 11 pruned. \n",
      "[I 2025-05-12 12:21:43,299] Trial 12 finished with value: 0.006160622272998463 and parameters: {'lr': 0.000276267077387634, 'weight_decay': 1.4501141521388748e-06, 'dropout': 0.2156208490534498, 'batch_size': 32, 'fusion_hidden_dim': 64, 'gnn_hidden_dim': 128, 'gnn_layers': 5, 'fp_hidden_dim': 1024, 'fp_layers': 4, 'interaction_hidden_dim': 64}. Best is trial 2 with value: 0.005692866564170944.\n",
      "[I 2025-05-12 12:21:48,325] Trial 13 pruned. \n",
      "[I 2025-05-12 12:23:36,133] Trial 14 pruned. \n",
      "[I 2025-05-12 12:26:08,779] Trial 15 pruned. \n",
      "[I 2025-05-12 12:26:38,549] Trial 16 pruned. \n",
      "[I 2025-05-12 12:26:49,381] Trial 17 pruned. \n",
      "[I 2025-05-12 12:33:49,113] Trial 18 finished with value: 0.005105014006517736 and parameters: {'lr': 0.00044659271504154317, 'weight_decay': 5.892297004051375e-06, 'dropout': 0.14016104299376342, 'batch_size': 128, 'fusion_hidden_dim': 512, 'gnn_hidden_dim': 128, 'gnn_layers': 5, 'fp_hidden_dim': 512, 'fp_layers': 2, 'interaction_hidden_dim': 32}. Best is trial 18 with value: 0.005105014006517736.\n",
      "[I 2025-05-12 12:37:17,334] Trial 19 pruned. \n",
      "[I 2025-05-12 12:37:27,935] Trial 20 pruned. \n",
      "[I 2025-05-12 12:37:39,033] Trial 21 pruned. \n",
      "[I 2025-05-12 12:42:51,018] Trial 22 finished with value: 0.005099041617167963 and parameters: {'lr': 0.0005520319369083573, 'weight_decay': 7.960133733548129e-06, 'dropout': 0.14451703122058876, 'batch_size': 128, 'fusion_hidden_dim': 128, 'gnn_hidden_dim': 128, 'gnn_layers': 4, 'fp_hidden_dim': 512, 'fp_layers': 2, 'interaction_hidden_dim': 32}. Best is trial 22 with value: 0.005099041617167963.\n",
      "[I 2025-05-12 12:45:21,653] Trial 23 pruned. \n",
      "[I 2025-05-12 12:46:15,798] Trial 24 pruned. \n",
      "[I 2025-05-12 12:49:45,490] Trial 25 pruned. \n",
      "[I 2025-05-12 12:51:17,661] Trial 26 pruned. \n",
      "[I 2025-05-12 12:51:20,816] Trial 27 pruned. \n",
      "[I 2025-05-12 12:55:42,760] Trial 28 pruned. \n",
      "[I 2025-05-12 12:56:54,488] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: Optuna finished. Duration: 5403.45 sec\n",
      "Fold 2: Optuna best hyperparameters:\n",
      " {'lr': 0.0005520319369083573, 'weight_decay': 7.960133733548129e-06, 'dropout': 0.14451703122058876, 'batch_size': 128, 'fusion_hidden_dim': 128, 'gnn_hidden_dim': 128, 'gnn_layers': 4, 'fp_hidden_dim': 512, 'fp_layers': 2, 'interaction_hidden_dim': 32}\n",
      "Fold 2: Best validation loss (Average MSE scaled): 0.005099\n",
      "\n",
      "--- Fold 2: Training final model ---\n",
      " F2 E010/250 | Tr L(S): 0.01426 | V L(S): 0.01228 | V SP MAE: 48.1482\n",
      " F2 E020/250 | Tr L(S): 0.00902 | V L(S): 0.00920 | V SP MAE: 43.1212\n",
      " F2 E030/250 | Tr L(S): 0.00615 | V L(S): 0.00851 | V SP MAE: 40.7687\n",
      " F2 E040/250 | Tr L(S): 0.00576 | V L(S): 0.00665 | V SP MAE: 41.1809\n",
      " F2 E050/250 | Tr L(S): 0.00471 | V L(S): 0.00604 | V SP MAE: 39.4237\n",
      " F2 E060/250 | Tr L(S): 0.00439 | V L(S): 0.00617 | V SP MAE: 37.6305\n",
      " F2 E070/250 | Tr L(S): 0.00391 | V L(S): 0.00611 | V SP MAE: 36.2376\n",
      " F2 E080/250 | Tr L(S): 0.00336 | V L(S): 0.00554 | V SP MAE: 36.1335\n",
      " F2 E090/250 | Tr L(S): 0.00306 | V L(S): 0.00544 | V SP MAE: 37.3802\n",
      " F2 E100/250 | Tr L(S): 0.00275 | V L(S): 0.00523 | V SP MAE: 39.8377\n",
      " F2 E110/250 | Tr L(S): 0.00217 | V L(S): 0.00484 | V SP MAE: 35.5368\n",
      " F2 E120/250 | Tr L(S): 0.00208 | V L(S): 0.00501 | V SP MAE: 35.5634\n",
      " F2 E130/250 | Tr L(S): 0.00171 | V L(S): 0.00486 | V SP MAE: 36.5013\n",
      " F2 E140/250 | Tr L(S): 0.00162 | V L(S): 0.00475 | V SP MAE: 35.4410\n",
      " F2 E150/250 | Tr L(S): 0.00152 | V L(S): 0.00480 | V SP MAE: 36.8243\n",
      " F2 E160/250 | Tr L(S): 0.00138 | V L(S): 0.00480 | V SP MAE: 36.8785\n",
      " F2 E170/250 | Tr L(S): 0.00135 | V L(S): 0.00481 | V SP MAE: 36.8878\n",
      " F2 E180/250 | Tr L(S): 0.00124 | V L(S): 0.00467 | V SP MAE: 36.0510\n",
      " F2 E190/250 | Tr L(S): 0.00126 | V L(S): 0.00471 | V SP MAE: 36.8971\n",
      " F2 E200/250 | Tr L(S): 0.00122 | V L(S): 0.00469 | V SP MAE: 36.2915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 13:08:01,117] A new study created in memory with name: no-name-209b15d8-5ef5-49f1-ab5a-f0a03e8abf62\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " F2 E210/250 | Tr L(S): 0.00123 | V L(S): 0.00468 | V SP MAE: 36.1258\n",
      "  Early stopping. Best Epoch: 180\n",
      "  Fold 2 training finished. Duration: 666.50 sec.\n",
      "  Fold 2 best model saved to: ./best_models_gine_mixfp_multitask_v3\\model_fold_2_best.pth (from epoch 180)\n",
      "\n",
      "===== Fold 3/5 =====\n",
      "Fold Train size: 10509, Fold Val size: 2627\n",
      "\n",
      "--- Fold 3: Fitting fold scalers per property ---\n",
      "Fold Train size after dropping unscalable samples: 10509\n",
      "Fold Val size after dropping unscalable samples: 2627\n",
      "\n",
      "--- Fold 3: Running Optuna ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 13:11:50,248] Trial 0 finished with value: 0.02514918297741892 and parameters: {'lr': 3.56600614763924e-05, 'weight_decay': 5.263335943985726e-06, 'dropout': 0.36800556082648483, 'batch_size': 64, 'fusion_hidden_dim': 64, 'gnn_hidden_dim': 128, 'gnn_layers': 4, 'fp_hidden_dim': 256, 'fp_layers': 3, 'interaction_hidden_dim': 128}. Best is trial 0 with value: 0.02514918297741892.\n",
      "[I 2025-05-12 13:17:34,378] Trial 1 finished with value: 0.00550929355664581 and parameters: {'lr': 8.60737798853748e-05, 'weight_decay': 6.903532698361291e-05, 'dropout': 0.11712187600411372, 'batch_size': 32, 'fusion_hidden_dim': 256, 'gnn_hidden_dim': 32, 'gnn_layers': 1, 'fp_hidden_dim': 1024, 'fp_layers': 2, 'interaction_hidden_dim': 64}. Best is trial 1 with value: 0.00550929355664581.\n",
      "[I 2025-05-12 13:19:41,820] Trial 2 finished with value: 0.010440456307892795 and parameters: {'lr': 4.9955111691236275e-05, 'weight_decay': 5.402478911933109e-05, 'dropout': 0.1995128935121068, 'batch_size': 128, 'fusion_hidden_dim': 128, 'gnn_hidden_dim': 32, 'gnn_layers': 1, 'fp_hidden_dim': 512, 'fp_layers': 3, 'interaction_hidden_dim': 128}. Best is trial 1 with value: 0.00550929355664581.\n",
      "[I 2025-05-12 13:38:07,630] Trial 3 finished with value: 0.006294895901028368 and parameters: {'lr': 0.0002358855020401207, 'weight_decay': 7.797338685874104e-05, 'dropout': 0.4286624103987343, 'batch_size': 32, 'fusion_hidden_dim': 512, 'gnn_hidden_dim': 256, 'gnn_layers': 4, 'fp_hidden_dim': 1024, 'fp_layers': 3, 'interaction_hidden_dim': 32}. Best is trial 1 with value: 0.00550929355664581.\n",
      "[I 2025-05-12 13:53:48,572] Trial 4 finished with value: 0.009054940722911103 and parameters: {'lr': 0.0002573095850699427, 'weight_decay': 2.2023759021750944e-05, 'dropout': 0.3166275263512448, 'batch_size': 32, 'fusion_hidden_dim': 256, 'gnn_hidden_dim': 256, 'gnn_layers': 5, 'fp_hidden_dim': 128, 'fp_layers': 4, 'interaction_hidden_dim': 64}. Best is trial 1 with value: 0.00550929355664581.\n",
      "[I 2025-05-12 13:54:01,049] Trial 5 pruned. \n",
      "[I 2025-05-12 13:54:06,571] Trial 6 pruned. \n",
      "[I 2025-05-12 13:54:18,129] Trial 7 pruned. \n",
      "[I 2025-05-12 13:54:26,142] Trial 8 pruned. \n",
      "[I 2025-05-12 13:54:31,772] Trial 9 pruned. \n",
      "[I 2025-05-12 13:54:39,469] Trial 10 pruned. \n",
      "[I 2025-05-12 13:54:46,214] Trial 11 pruned. \n",
      "[I 2025-05-12 13:55:08,475] Trial 12 pruned. \n",
      "[I 2025-05-12 13:55:25,591] Trial 13 pruned. \n",
      "[I 2025-05-12 13:55:33,738] Trial 14 pruned. \n",
      "[I 2025-05-12 13:55:39,755] Trial 15 pruned. \n",
      "[I 2025-05-12 13:55:46,534] Trial 16 pruned. \n",
      "[I 2025-05-12 13:55:51,515] Trial 17 pruned. \n",
      "[I 2025-05-12 13:56:04,671] Trial 18 pruned. \n",
      "[I 2025-05-12 13:56:06,783] Trial 19 pruned. \n",
      "[I 2025-05-12 13:57:50,149] Trial 20 pruned. \n",
      "[I 2025-05-12 13:57:57,936] Trial 21 pruned. \n",
      "[I 2025-05-12 13:58:28,929] Trial 22 pruned. \n",
      "[I 2025-05-12 13:59:00,582] Trial 23 pruned. \n",
      "[I 2025-05-12 13:59:07,379] Trial 24 pruned. \n",
      "[I 2025-05-12 13:59:24,445] Trial 25 pruned. \n",
      "[I 2025-05-12 13:59:34,149] Trial 26 pruned. \n",
      "[I 2025-05-12 14:11:25,999] Trial 27 finished with value: 0.007050914346523137 and parameters: {'lr': 0.0004897886118466695, 'weight_decay': 7.139572463856096e-05, 'dropout': 0.40037032915214327, 'batch_size': 32, 'fusion_hidden_dim': 64, 'gnn_hidden_dim': 64, 'gnn_layers': 4, 'fp_hidden_dim': 1024, 'fp_layers': 4, 'interaction_hidden_dim': 64}. Best is trial 1 with value: 0.00550929355664581.\n",
      "[I 2025-05-12 14:11:34,493] Trial 28 pruned. \n",
      "[I 2025-05-12 14:11:40,257] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: Optuna finished. Duration: 3819.14 sec\n",
      "Fold 3: Optuna best hyperparameters:\n",
      " {'lr': 8.60737798853748e-05, 'weight_decay': 6.903532698361291e-05, 'dropout': 0.11712187600411372, 'batch_size': 32, 'fusion_hidden_dim': 256, 'gnn_hidden_dim': 32, 'gnn_layers': 1, 'fp_hidden_dim': 1024, 'fp_layers': 2, 'interaction_hidden_dim': 64}\n",
      "Fold 3: Best validation loss (Average MSE scaled): 0.005509\n",
      "\n",
      "--- Fold 3: Training final model ---\n",
      " F3 E010/250 | Tr L(S): 0.01228 | V L(S): 0.01144 | V SP MAE: 44.0870\n",
      " F3 E020/250 | Tr L(S): 0.00767 | V L(S): 0.00827 | V SP MAE: 40.8398\n",
      " F3 E030/250 | Tr L(S): 0.00564 | V L(S): 0.01565 | V SP MAE: 42.3285\n",
      " F3 E040/250 | Tr L(S): 0.00482 | V L(S): 0.00684 | V SP MAE: 37.8271\n",
      " F3 E050/250 | Tr L(S): 0.00409 | V L(S): 0.00568 | V SP MAE: 37.0381\n",
      " F3 E060/250 | Tr L(S): 0.00388 | V L(S): 0.00658 | V SP MAE: 33.1386\n",
      " F3 E070/250 | Tr L(S): 0.00362 | V L(S): 0.00647 | V SP MAE: 37.0322\n",
      " F3 E080/250 | Tr L(S): 0.00326 | V L(S): 0.00552 | V SP MAE: 31.0699\n",
      " F3 E090/250 | Tr L(S): 0.00314 | V L(S): 0.00538 | V SP MAE: 33.6718\n",
      " F3 E100/250 | Tr L(S): 0.00303 | V L(S): 0.00557 | V SP MAE: 30.1958\n",
      " F3 E110/250 | Tr L(S): 0.00295 | V L(S): 0.00513 | V SP MAE: 31.1523\n",
      " F3 E120/250 | Tr L(S): 0.00277 | V L(S): 0.00490 | V SP MAE: 29.3577\n",
      " F3 E130/250 | Tr L(S): 0.00270 | V L(S): 0.00552 | V SP MAE: 33.3872\n",
      " F3 E140/250 | Tr L(S): 0.00215 | V L(S): 0.00481 | V SP MAE: 32.2738\n",
      " F3 E150/250 | Tr L(S): 0.00206 | V L(S): 0.00473 | V SP MAE: 29.3779\n",
      " F3 E160/250 | Tr L(S): 0.00194 | V L(S): 0.00488 | V SP MAE: 28.8240\n",
      " F3 E170/250 | Tr L(S): 0.00171 | V L(S): 0.00469 | V SP MAE: 30.6608\n",
      " F3 E180/250 | Tr L(S): 0.00163 | V L(S): 0.00479 | V SP MAE: 29.5704\n",
      " F3 E190/250 | Tr L(S): 0.00151 | V L(S): 0.00457 | V SP MAE: 29.6073\n",
      " F3 E200/250 | Tr L(S): 0.00148 | V L(S): 0.00457 | V SP MAE: 28.8987\n",
      " F3 E210/250 | Tr L(S): 0.00143 | V L(S): 0.00460 | V SP MAE: 29.6478\n",
      " F3 E220/250 | Tr L(S): 0.00140 | V L(S): 0.00457 | V SP MAE: 29.4912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 14:30:48,242] A new study created in memory with name: no-name-90ad06b7-f77f-4746-a175-13ba0061054e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " F3 E229/250 | Tr L(S): 0.00139 | V L(S): 0.00458 | V SP MAE: 29.2085\n",
      "  Early stopping. Best Epoch: 199\n",
      "  Fold 3 training finished. Duration: 1147.81 sec.\n",
      "  Fold 3 best model saved to: ./best_models_gine_mixfp_multitask_v3\\model_fold_3_best.pth (from epoch 199)\n",
      "\n",
      "===== Fold 4/5 =====\n",
      "Fold Train size: 10509, Fold Val size: 2627\n",
      "\n",
      "--- Fold 4: Fitting fold scalers per property ---\n",
      "Fold Train size after dropping unscalable samples: 10509\n",
      "Fold Val size after dropping unscalable samples: 2627\n",
      "\n",
      "--- Fold 4: Running Optuna ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 14:35:32,061] Trial 0 finished with value: 0.010883994106306109 and parameters: {'lr': 1.53529146628892e-05, 'weight_decay': 6.177681746502137e-06, 'dropout': 0.15963447435887332, 'batch_size': 128, 'fusion_hidden_dim': 64, 'gnn_hidden_dim': 32, 'gnn_layers': 4, 'fp_hidden_dim': 512, 'fp_layers': 3, 'interaction_hidden_dim': 64}. Best is trial 0 with value: 0.010883994106306109.\n",
      "[I 2025-05-12 14:41:47,486] Trial 1 finished with value: 0.005009107056430955 and parameters: {'lr': 0.0005916049746876524, 'weight_decay': 6.9141419954794405e-06, 'dropout': 0.14756607171305475, 'batch_size': 64, 'fusion_hidden_dim': 512, 'gnn_hidden_dim': 64, 'gnn_layers': 5, 'fp_hidden_dim': 128, 'fp_layers': 2, 'interaction_hidden_dim': 128}. Best is trial 1 with value: 0.005009107056430955.\n",
      "[I 2025-05-12 14:52:15,293] Trial 2 finished with value: 0.008135188152068972 and parameters: {'lr': 0.00017640254686812477, 'weight_decay': 4.376744164109263e-05, 'dropout': 0.23999763764610363, 'batch_size': 128, 'fusion_hidden_dim': 128, 'gnn_hidden_dim': 256, 'gnn_layers': 4, 'fp_hidden_dim': 512, 'fp_layers': 1, 'interaction_hidden_dim': 32}. Best is trial 1 with value: 0.005009107056430955.\n",
      "[I 2025-05-12 14:53:58,238] Trial 3 finished with value: 0.017044716406539154 and parameters: {'lr': 3.358085161344177e-05, 'weight_decay': 1.1772708202813725e-05, 'dropout': 0.28799093583289137, 'batch_size': 128, 'fusion_hidden_dim': 256, 'gnn_hidden_dim': 32, 'gnn_layers': 5, 'fp_hidden_dim': 128, 'fp_layers': 1, 'interaction_hidden_dim': 128}. Best is trial 1 with value: 0.005009107056430955.\n",
      "[I 2025-05-12 14:56:20,720] Trial 4 finished with value: 0.01456287228630822 and parameters: {'lr': 0.00012676101898572467, 'weight_decay': 1.0098558007465692e-06, 'dropout': 0.2581912397089009, 'batch_size': 64, 'fusion_hidden_dim': 64, 'gnn_hidden_dim': 128, 'gnn_layers': 3, 'fp_hidden_dim': 512, 'fp_layers': 2, 'interaction_hidden_dim': 128}. Best is trial 1 with value: 0.005009107056430955.\n",
      "[I 2025-05-12 14:56:42,963] Trial 5 pruned. \n",
      "[I 2025-05-12 14:57:06,901] Trial 6 pruned. \n",
      "[I 2025-05-12 14:57:22,703] Trial 7 pruned. \n",
      "[I 2025-05-12 14:57:26,068] Trial 8 pruned. \n",
      "[I 2025-05-12 14:57:33,533] Trial 9 pruned. \n",
      "[I 2025-05-12 14:57:45,864] Trial 10 pruned. \n",
      "[I 2025-05-12 15:10:22,441] Trial 11 finished with value: 0.005526179127877208 and parameters: {'lr': 0.000990767355138874, 'weight_decay': 8.88276944030091e-05, 'dropout': 0.19922439346612583, 'batch_size': 64, 'fusion_hidden_dim': 128, 'gnn_hidden_dim': 256, 'gnn_layers': 4, 'fp_hidden_dim': 256, 'fp_layers': 2, 'interaction_hidden_dim': 32}. Best is trial 1 with value: 0.005009107056430955.\n",
      "[I 2025-05-12 15:22:28,406] Trial 12 finished with value: 0.005119105086765553 and parameters: {'lr': 0.0009504348477740804, 'weight_decay': 9.626392058837635e-05, 'dropout': 0.17858834588073869, 'batch_size': 64, 'fusion_hidden_dim': 128, 'gnn_hidden_dim': 256, 'gnn_layers': 5, 'fp_hidden_dim': 256, 'fp_layers': 2, 'interaction_hidden_dim': 32}. Best is trial 1 with value: 0.005009107056430955.\n",
      "[I 2025-05-12 15:29:52,766] Trial 13 pruned. \n",
      "[I 2025-05-12 15:29:55,925] Trial 14 pruned. \n",
      "[I 2025-05-12 15:30:02,242] Trial 15 pruned. \n",
      "[I 2025-05-12 15:33:45,479] Trial 16 finished with value: 0.005280632918681081 and parameters: {'lr': 0.0005931705217285468, 'weight_decay': 2.8435126937259633e-06, 'dropout': 0.23792475533541796, 'batch_size': 64, 'fusion_hidden_dim': 128, 'gnn_hidden_dim': 64, 'gnn_layers': 2, 'fp_hidden_dim': 128, 'fp_layers': 2, 'interaction_hidden_dim': 128}. Best is trial 1 with value: 0.005009107056430955.\n",
      "[I 2025-05-12 15:33:50,304] Trial 17 pruned. \n",
      "[I 2025-05-12 15:33:53,177] Trial 18 pruned. \n",
      "[I 2025-05-12 15:39:15,689] Trial 19 finished with value: 0.006495983370417617 and parameters: {'lr': 0.0009566766560479257, 'weight_decay': 8.729864492405061e-05, 'dropout': 0.15586086058082754, 'batch_size': 64, 'fusion_hidden_dim': 512, 'gnn_hidden_dim': 256, 'gnn_layers': 5, 'fp_hidden_dim': 128, 'fp_layers': 3, 'interaction_hidden_dim': 64}. Best is trial 1 with value: 0.005009107056430955.\n",
      "[I 2025-05-12 15:39:21,623] Trial 20 pruned. \n",
      "[I 2025-05-12 15:39:26,402] Trial 21 pruned. \n",
      "[I 2025-05-12 15:43:00,502] Trial 22 finished with value: 0.005040410812589722 and parameters: {'lr': 0.0005811326516971937, 'weight_decay': 1.781835765535478e-06, 'dropout': 0.1411655106940428, 'batch_size': 64, 'fusion_hidden_dim': 128, 'gnn_hidden_dim': 64, 'gnn_layers': 2, 'fp_hidden_dim': 128, 'fp_layers': 2, 'interaction_hidden_dim': 128}. Best is trial 1 with value: 0.005009107056430955.\n",
      "[I 2025-05-12 15:47:31,858] Trial 23 finished with value: 0.00480880102383719 and parameters: {'lr': 0.0006063540019669372, 'weight_decay': 1.119531247114424e-06, 'dropout': 0.1394598502764331, 'batch_size': 64, 'fusion_hidden_dim': 128, 'gnn_hidden_dim': 64, 'gnn_layers': 2, 'fp_hidden_dim': 128, 'fp_layers': 2, 'interaction_hidden_dim': 128}. Best is trial 23 with value: 0.00480880102383719.\n",
      "[I 2025-05-12 15:47:39,824] Trial 24 pruned. \n",
      "[I 2025-05-12 15:51:39,130] Trial 25 finished with value: 0.004785154056473929 and parameters: {'lr': 0.00042154979130198494, 'weight_decay': 1.659471617105183e-06, 'dropout': 0.13855465762222516, 'batch_size': 64, 'fusion_hidden_dim': 128, 'gnn_hidden_dim': 64, 'gnn_layers': 1, 'fp_hidden_dim': 128, 'fp_layers': 2, 'interaction_hidden_dim': 128}. Best is trial 25 with value: 0.004785154056473929.\n",
      "[I 2025-05-12 15:51:41,133] Trial 26 pruned. \n",
      "[I 2025-05-12 15:51:45,404] Trial 27 pruned. \n",
      "[I 2025-05-12 15:51:48,879] Trial 28 pruned. \n",
      "[I 2025-05-12 15:51:51,417] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: Optuna finished. Duration: 4863.18 sec\n",
      "Fold 4: Optuna best hyperparameters:\n",
      " {'lr': 0.00042154979130198494, 'weight_decay': 1.659471617105183e-06, 'dropout': 0.13855465762222516, 'batch_size': 64, 'fusion_hidden_dim': 128, 'gnn_hidden_dim': 64, 'gnn_layers': 1, 'fp_hidden_dim': 128, 'fp_layers': 2, 'interaction_hidden_dim': 128}\n",
      "Fold 4: Best validation loss (Average MSE scaled): 0.004785\n",
      "\n",
      "--- Fold 4: Training final model ---\n",
      " F4 E010/250 | Tr L(S): 0.01365 | V L(S): 0.01063 | V SP MAE: 50.6282\n",
      " F4 E020/250 | Tr L(S): 0.00866 | V L(S): 0.00991 | V SP MAE: 47.2972\n",
      " F4 E030/250 | Tr L(S): 0.00634 | V L(S): 0.00676 | V SP MAE: 40.7468\n",
      " F4 E040/250 | Tr L(S): 0.00540 | V L(S): 0.00606 | V SP MAE: 41.6347\n",
      " F4 E050/250 | Tr L(S): 0.00448 | V L(S): 0.00632 | V SP MAE: 37.7267\n",
      " F4 E060/250 | Tr L(S): 0.00400 | V L(S): 0.00542 | V SP MAE: 36.8854\n",
      " F4 E070/250 | Tr L(S): 0.00377 | V L(S): 0.00561 | V SP MAE: 34.5121\n",
      " F4 E080/250 | Tr L(S): 0.00337 | V L(S): 0.00531 | V SP MAE: 33.9822\n",
      " F4 E090/250 | Tr L(S): 0.00287 | V L(S): 0.00485 | V SP MAE: 36.5401\n",
      " F4 E100/250 | Tr L(S): 0.00261 | V L(S): 0.00499 | V SP MAE: 36.4467\n",
      " F4 E110/250 | Tr L(S): 0.00271 | V L(S): 0.00487 | V SP MAE: 34.8911\n",
      " F4 E120/250 | Tr L(S): 0.00253 | V L(S): 0.00510 | V SP MAE: 35.0331\n",
      " F4 E130/250 | Tr L(S): 0.00233 | V L(S): 0.00488 | V SP MAE: 35.9249\n",
      " F4 E140/250 | Tr L(S): 0.00239 | V L(S): 0.00501 | V SP MAE: 33.1568\n",
      " F4 E150/250 | Tr L(S): 0.00211 | V L(S): 0.00487 | V SP MAE: 35.2869\n",
      " F4 E160/250 | Tr L(S): 0.00212 | V L(S): 0.00475 | V SP MAE: 34.3031\n",
      " F4 E170/250 | Tr L(S): 0.00199 | V L(S): 0.00472 | V SP MAE: 33.8686\n",
      " F4 E180/250 | Tr L(S): 0.00200 | V L(S): 0.00469 | V SP MAE: 34.1393\n",
      " F4 E190/250 | Tr L(S): 0.00185 | V L(S): 0.00471 | V SP MAE: 33.6945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 16:00:29,158] A new study created in memory with name: no-name-858d2a23-348a-4594-a22d-9d541ca5f8ee\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " F4 E195/250 | Tr L(S): 0.00187 | V L(S): 0.00475 | V SP MAE: 33.0476\n",
      "  Early stopping. Best Epoch: 165\n",
      "  Fold 4 training finished. Duration: 517.63 sec.\n",
      "  Fold 4 best model saved to: ./best_models_gine_mixfp_multitask_v3\\model_fold_4_best.pth (from epoch 165)\n",
      "\n",
      "===== Fold 5/5 =====\n",
      "Fold Train size: 10509, Fold Val size: 2627\n",
      "\n",
      "--- Fold 5: Fitting fold scalers per property ---\n",
      "Fold Train size after dropping unscalable samples: 10509\n",
      "Fold Val size after dropping unscalable samples: 2627\n",
      "\n",
      "--- Fold 5: Running Optuna ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 16:07:22,199] Trial 0 finished with value: 0.005956766324084106 and parameters: {'lr': 0.00031559294561399104, 'weight_decay': 9.450062288052563e-05, 'dropout': 0.40468435373710976, 'batch_size': 64, 'fusion_hidden_dim': 128, 'gnn_hidden_dim': 32, 'gnn_layers': 3, 'fp_hidden_dim': 512, 'fp_layers': 1, 'interaction_hidden_dim': 32}. Best is trial 0 with value: 0.005956766324084106.\n",
      "[I 2025-05-12 16:08:56,017] Trial 1 finished with value: 0.021631675119291136 and parameters: {'lr': 3.5216853698199856e-05, 'weight_decay': 2.264600647087025e-06, 'dropout': 0.3553321198958326, 'batch_size': 64, 'fusion_hidden_dim': 512, 'gnn_hidden_dim': 128, 'gnn_layers': 5, 'fp_hidden_dim': 1024, 'fp_layers': 3, 'interaction_hidden_dim': 32}. Best is trial 0 with value: 0.005956766324084106.\n",
      "[I 2025-05-12 16:09:32,131] Trial 2 finished with value: 0.02182381589862418 and parameters: {'lr': 3.959557718503262e-05, 'weight_decay': 5.095304580030697e-05, 'dropout': 0.45913993407846143, 'batch_size': 128, 'fusion_hidden_dim': 512, 'gnn_hidden_dim': 32, 'gnn_layers': 1, 'fp_hidden_dim': 512, 'fp_layers': 2, 'interaction_hidden_dim': 32}. Best is trial 0 with value: 0.005956766324084106.\n",
      "[I 2025-05-12 16:11:14,506] Trial 3 finished with value: 0.00978947150388947 and parameters: {'lr': 0.00022559563964425047, 'weight_decay': 6.813057962698467e-05, 'dropout': 0.15660474045132022, 'batch_size': 128, 'fusion_hidden_dim': 64, 'gnn_hidden_dim': 64, 'gnn_layers': 1, 'fp_hidden_dim': 128, 'fp_layers': 2, 'interaction_hidden_dim': 64}. Best is trial 0 with value: 0.005956766324084106.\n",
      "[I 2025-05-12 16:15:52,494] Trial 4 finished with value: 0.010990499439946138 and parameters: {'lr': 8.72927698731894e-05, 'weight_decay': 6.7113756776607446e-06, 'dropout': 0.18924735530573045, 'batch_size': 32, 'fusion_hidden_dim': 128, 'gnn_hidden_dim': 64, 'gnn_layers': 2, 'fp_hidden_dim': 1024, 'fp_layers': 4, 'interaction_hidden_dim': 128}. Best is trial 0 with value: 0.005956766324084106.\n",
      "[I 2025-05-12 16:15:56,777] Trial 5 pruned. \n",
      "[I 2025-05-12 16:15:59,634] Trial 6 pruned. \n",
      "[I 2025-05-12 16:16:02,684] Trial 7 pruned. \n",
      "[I 2025-05-12 16:16:05,360] Trial 8 pruned. \n",
      "[I 2025-05-12 16:16:09,760] Trial 9 pruned. \n",
      "[I 2025-05-12 16:16:14,328] Trial 10 pruned. \n",
      "[I 2025-05-12 16:20:51,223] Trial 11 finished with value: 0.005776672684308408 and parameters: {'lr': 0.0009263862243706357, 'weight_decay': 9.453274739860927e-05, 'dropout': 0.23233595885106373, 'batch_size': 128, 'fusion_hidden_dim': 64, 'gnn_hidden_dim': 32, 'gnn_layers': 3, 'fp_hidden_dim': 128, 'fp_layers': 2, 'interaction_hidden_dim': 64}. Best is trial 11 with value: 0.005776672684308408.\n",
      "[I 2025-05-12 16:24:11,219] Trial 12 finished with value: 0.0058723373106414085 and parameters: {'lr': 0.0009835928217886627, 'weight_decay': 9.97570534431845e-05, 'dropout': 0.24079575999213515, 'batch_size': 128, 'fusion_hidden_dim': 64, 'gnn_hidden_dim': 32, 'gnn_layers': 3, 'fp_hidden_dim': 128, 'fp_layers': 1, 'interaction_hidden_dim': 64}. Best is trial 11 with value: 0.005776672684308408.\n",
      "[I 2025-05-12 16:26:53,417] Trial 13 pruned. \n",
      "[I 2025-05-12 16:27:44,927] Trial 14 pruned. \n",
      "[I 2025-05-12 16:28:41,379] Trial 15 pruned. \n",
      "[I 2025-05-12 16:28:50,090] Trial 16 pruned. \n",
      "[I 2025-05-12 16:29:08,790] Trial 17 pruned. \n",
      "[I 2025-05-12 16:29:52,345] Trial 18 pruned. \n",
      "[I 2025-05-12 16:30:06,131] Trial 19 pruned. \n",
      "[I 2025-05-12 16:30:11,337] Trial 20 pruned. \n",
      "[I 2025-05-12 16:30:22,639] Trial 21 pruned. \n",
      "[I 2025-05-12 16:30:28,517] Trial 22 pruned. \n",
      "[I 2025-05-12 16:30:39,037] Trial 23 pruned. \n",
      "[I 2025-05-12 16:30:47,229] Trial 24 pruned. \n",
      "[I 2025-05-12 16:30:50,889] Trial 25 pruned. \n",
      "[I 2025-05-12 16:34:42,422] Trial 26 finished with value: 0.005902920426937311 and parameters: {'lr': 0.0007228885345159045, 'weight_decay': 4.9445669634322234e-05, 'dropout': 0.3155993543694042, 'batch_size': 128, 'fusion_hidden_dim': 128, 'gnn_hidden_dim': 32, 'gnn_layers': 3, 'fp_hidden_dim': 1024, 'fp_layers': 1, 'interaction_hidden_dim': 64}. Best is trial 11 with value: 0.005776672684308408.\n",
      "[I 2025-05-12 16:34:50,756] Trial 27 pruned. \n",
      "[I 2025-05-12 16:35:26,136] Trial 28 pruned. \n",
      "[I 2025-05-12 16:35:28,264] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: Optuna finished. Duration: 2099.11 sec\n",
      "Fold 5: Optuna best hyperparameters:\n",
      " {'lr': 0.0009263862243706357, 'weight_decay': 9.453274739860927e-05, 'dropout': 0.23233595885106373, 'batch_size': 128, 'fusion_hidden_dim': 64, 'gnn_hidden_dim': 32, 'gnn_layers': 3, 'fp_hidden_dim': 128, 'fp_layers': 2, 'interaction_hidden_dim': 64}\n",
      "Fold 5: Best validation loss (Average MSE scaled): 0.005777\n",
      "\n",
      "--- Fold 5: Training final model ---\n",
      " F5 E010/250 | Tr L(S): 0.01620 | V L(S): 0.01543 | V SP MAE: 49.8122\n",
      " F5 E020/250 | Tr L(S): 0.01147 | V L(S): 0.00918 | V SP MAE: 45.9640\n",
      " F5 E030/250 | Tr L(S): 0.00956 | V L(S): 0.00820 | V SP MAE: 42.0860\n",
      " F5 E040/250 | Tr L(S): 0.00845 | V L(S): 0.00692 | V SP MAE: 44.0542\n",
      " F5 E050/250 | Tr L(S): 0.00767 | V L(S): 0.00664 | V SP MAE: 43.7780\n",
      " F5 E060/250 | Tr L(S): 0.00730 | V L(S): 0.00714 | V SP MAE: 41.4413\n",
      " F5 E070/250 | Tr L(S): 0.00684 | V L(S): 0.00654 | V SP MAE: 40.0093\n",
      " F5 E080/250 | Tr L(S): 0.00690 | V L(S): 0.00659 | V SP MAE: 42.4421\n",
      " F5 E090/250 | Tr L(S): 0.00607 | V L(S): 0.00569 | V SP MAE: 41.7852\n",
      " F5 E100/250 | Tr L(S): 0.00524 | V L(S): 0.00536 | V SP MAE: 37.5395\n",
      " F5 E110/250 | Tr L(S): 0.00547 | V L(S): 0.00561 | V SP MAE: 37.5233\n",
      " F5 E120/250 | Tr L(S): 0.00440 | V L(S): 0.00498 | V SP MAE: 36.3188\n",
      " F5 E130/250 | Tr L(S): 0.00418 | V L(S): 0.00501 | V SP MAE: 36.9733\n",
      " F5 E140/250 | Tr L(S): 0.00382 | V L(S): 0.00467 | V SP MAE: 37.0563\n",
      " F5 E150/250 | Tr L(S): 0.00377 | V L(S): 0.00480 | V SP MAE: 37.2183\n",
      " F5 E160/250 | Tr L(S): 0.00355 | V L(S): 0.00457 | V SP MAE: 36.4053\n",
      " F5 E170/250 | Tr L(S): 0.00352 | V L(S): 0.00458 | V SP MAE: 36.4672\n",
      " F5 E180/250 | Tr L(S): 0.00342 | V L(S): 0.00458 | V SP MAE: 37.2331\n",
      " F5 E190/250 | Tr L(S): 0.00318 | V L(S): 0.00464 | V SP MAE: 35.6939\n",
      " F5 E200/250 | Tr L(S): 0.00323 | V L(S): 0.00453 | V SP MAE: 37.6615\n",
      " F5 E210/250 | Tr L(S): 0.00329 | V L(S): 0.00465 | V SP MAE: 36.0495\n",
      " F5 E220/250 | Tr L(S): 0.00324 | V L(S): 0.00457 | V SP MAE: 35.8778\n",
      " F5 E230/250 | Tr L(S): 0.00318 | V L(S): 0.00460 | V SP MAE: 35.9690\n",
      " F5 E239/250 | Tr L(S): 0.00314 | V L(S): 0.00456 | V SP MAE: 35.9243\n",
      "  Early stopping. Best Epoch: 209\n",
      "  Fold 5 training finished. Duration: 589.78 sec.\n",
      "  Fold 5 best model saved to: ./best_models_gine_mixfp_multitask_v3\\model_fold_5_best.pth (from epoch 209)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch_geometric.warnings\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "import joblib\n",
    "from collections import OrderedDict\n",
    "import copy\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, ReLU, Dropout, Sequential, BatchNorm1d\n",
    "\n",
    "from torch_geometric.nn import GINEConv, global_mean_pool, global_add_pool, global_max_pool\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import RDLogger\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "from skfp.fingerprints import PubChemFingerprint\n",
    "import optuna\n",
    "\n",
    "CSV_PATH = '../dataset/MT-thermal.csv'\n",
    "SMILES_COL = 'smiles'\n",
    "VALUE_COL = 'val'\n",
    "PROP_COL = 'prop'\n",
    "\n",
    "TEST_SPLIT_RATIO = 0.2\n",
    "VALIDATION_SPLIT_OPTUNA = 0.2\n",
    "RANDOM_STATE = 0\n",
    "N_FOLDS = 5\n",
    "N_TRIALS_OPTUNA = 30\n",
    "N_EPOCHS_FOLD_TRAINING = 250\n",
    "PATIENCE_FOLD_TRAINING = 30\n",
    "BEST_MODEL_SAVE_DIR = './best_models_gine_mixfp_multitask_v3'\n",
    "TEST_SET_RESULTS_FILE = 'results_gine_mixfp_multitask_v3.txt'\n",
    "SCALERS_SAVE_FILE = 'multitask_minmax_scalers.joblib'\n",
    "TARGET_COLS_FILE = 'target_cols_multitask.joblib'\n",
    "PREGENERATED_DATA_FILE = 'pregenerated_data.joblib'\n",
    "\n",
    "os.makedirs(BEST_MODEL_SAVE_DIR, exist_ok=True)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "element_names = [\n",
    "    \"C\", \"N\", \"O\", \"S\", \"F\", \"Si\", \"P\", \"Cl\", \"Br\", \"Mg\", \"Na\",\n",
    "    \"Ca\", \"Fe\", \"As\", \"Al\", \"I\", \"B\", \"V\", \"K\", \"Tl\", \"Yb\",\n",
    "    \"Sb\", \"Sn\", \"Ag\", \"Pd\", \"Co\", \"Se\", \"Ti\", \"Zn\", \"H\",\n",
    "    \"Li\", \"Ge\", \"Cu\", \"Au\", \"Ni\", \"Cd\", \"In\", \"Mn\", \"Zr\",\n",
    "    \"Cr\", \"Pt\", \"Hg\", \"Pb\", \"Unknown\",\"*\"\n",
    "]\n",
    "\n",
    "def one_of_k_encoding(x, allowable_set):\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "@dataclass\n",
    "class BondConfig:\n",
    "    bond_type: bool; conjugation: bool; ring: bool; stereo: bool = False; bond_dir: bool = False\n",
    "    def __post_init__(self):\n",
    "        self.n_features = 0; self.feat_names = []\n",
    "        if self.bond_type: self.n_features += 4; self.feat_names += [\"Single\", \"Double\", \"Triple\", \"Aromatic\"]\n",
    "        if self.conjugation: self.n_features += 1; self.feat_names += [\"Conjugation\"]\n",
    "        if self.ring: self.n_features += 1; self.feat_names += [\"inRing\"]\n",
    "        if self.stereo: self.n_features += 6; self.feat_names += [\"any\", \"cis\", \"e\", \"none\", \"trans\", \"z\"]\n",
    "        if self.bond_dir: self.n_features += 7; self.feat_names += [\"begin_dash\", \"begin_wedge\", \"either_double\", \"end_down_right\", \"end_up_right\", \"none\", \"unknown\"]\n",
    "\n",
    "@dataclass\n",
    "class AtomConfig:\n",
    "    element_type: bool; degree: bool; implicit_valence: bool; formal_charge: bool\n",
    "    num_rad_e: bool; hybridization: bool; combo_hybrid: bool = False\n",
    "    aromatic: bool = False; chirality: bool = False\n",
    "    def __post_init__(self):\n",
    "        self.n_features = 0; self.feat_names = []\n",
    "        def update(names): self.feat_names += names; self.n_features += len(names)\n",
    "        if self.element_type: update(element_names)\n",
    "        if self.degree: update([f\"degree{ind}\" for ind in range(11)])\n",
    "        if self.implicit_valence: update([f\"implicitValence{ind}\" for ind in range(7)])\n",
    "        if self.formal_charge: update([\"formalCharge\"])\n",
    "        if self.num_rad_e: update([\"numRadElectons\"])\n",
    "        if self.hybridization:\n",
    "            options = [\"HybridizationType.SP\", \"HybridizationType.SP2or3\", \"HybridizationType.SP3D\", \"HybridizationType.SP3D2\"] if self.combo_hybrid \\\n",
    "                 else [\"HybridizationType.SP\", \"HybridizationType.SP2\", \"HybridizationType.SP3\", \"HybridizationType.SP3D\", \"HybridizationType.SP3D2\"]\n",
    "            update(options)\n",
    "        if self.aromatic: update([\"Aromatic\"])\n",
    "        if self.chirality: update([\"Unspecified\", \"Tetrahedral_CW\", \"Tetrahedral_CCW\", \"CHI_OTHER\", \"Tetrahedral\", \"Allene\", \"Square_planar\", \"Trigonal_bipyramidal\", \"Octahedral\"]) # Fixed CHI_OTHER typo and order\n",
    "\n",
    "def bond_fp(bond, config: BondConfig):\n",
    "    bond_feats = []\n",
    "    if config.bond_type: bt = bond.GetBondType(); bond_feats += [bt == Chem.rdchem.BondType.SINGLE, bt == Chem.rdchem.BondType.DOUBLE, bt == Chem.rdchem.BondType.TRIPLE, bt == Chem.rdchem.BondType.AROMATIC]\n",
    "    if config.conjugation: bond_feats.append(bond.GetIsConjugated())\n",
    "    if config.ring: bond_feats.append(bond.IsInRing())\n",
    "    if config.stereo: st = bond.GetStereo(); bond_feats += [st == Chem.rdchem.BondStereo.STEREOANY, st == Chem.rdchem.BondStereo.STEREOCIS, st == Chem.rdchem.BondStereo.STEREOE, st == Chem.rdchem.BondStereo.STEREONONE, st == Chem.rdchem.BondStereo.STEREOTRANS, st == Chem.rdchem.BondStereo.STEREOZ]\n",
    "    if config.bond_dir: bd = bond.GetBondDir(); bond_feats += [bd == Chem.rdchem.BondDir.BEGINDASH, bd == Chem.rdchem.BondDir.BEGINWEDGE, bd == Chem.rdchem.BondDir.EITHERDOUBLE, bd == Chem.rdchem.BondDir.ENDDOWNRIGHT, bd == Chem.rdchem.BondDir.ENDUPRIGHT, bd == Chem.rdchem.BondDir.NONE, bd == Chem.rdchem.BondDir.UNKNOWN]\n",
    "    return [float(f) for f in bond_feats]\n",
    "\n",
    "def atom_fp(atom, config: AtomConfig):\n",
    "    results = []\n",
    "    if config.element_type: results += one_of_k_encoding_unk(atom.GetSymbol(), element_names)\n",
    "    if config.degree: results += one_of_k_encoding(atom.GetDegree(), list(range(11)))\n",
    "    if config.implicit_valence: results += one_of_k_encoding_unk(atom.GetImplicitValence(), list(range(7)))\n",
    "    if config.formal_charge: results += [atom.GetFormalCharge()]\n",
    "    if config.num_rad_e: results += [atom.GetNumRadicalElectrons()]\n",
    "    if config.hybridization:\n",
    "        feat = atom.GetHybridization()\n",
    "        options = [\"HybridizationType.SP\", \"HybridizationType.SP2or3\", \"HybridizationType.SP3D\", \"HybridizationType.SP3D2\"] if config.combo_hybrid and (feat == Chem.rdchem.HybridizationType.SP2 or feat == Chem.rdchem.HybridizationType.SP3) \\\n",
    "             else [\"HybridizationType.SP\", \"HybridizationType.SP2\", \"HybridizationType.SP3\", \"HybridizationType.SP3D\", \"HybridizationType.SP3D2\"]\n",
    "        current_feat = \"SP2/3\" if config.combo_hybrid and (feat == Chem.rdchem.HybridizationType.SP2 or feat == Chem.rdchem.HybridizationType.SP3) else feat\n",
    "        results += one_of_k_encoding_unk(current_feat, options)\n",
    "    if config.aromatic: results += [atom.GetIsAromatic()]\n",
    "    if config.chirality: tag = str(atom.GetChiralTag()); results += [tag == \"CHI_UNSPECIFIED\", tag == \"CHI_TETRAHEDRAL_CW\", tag == \"CHI_TETRAHEDRAL_CCW\", tag == \"CHI_OTHER\", tag == \"CHI_TETRAHEDRAL\", tag == \"CHI_ALLENE\", tag == \"CHI_SQUAREPLANAR\", tag == \"CHI_TRIGONALBIPYRAMIDAL\", tag == \"CHI_OCTAHEDRAL\"]\n",
    "    return [float(f) for f in results]\n",
    "# --- END OF STRICTLY PROVIDED ATOM_FP FUNCTION ---\n",
    "\n",
    "# --- Define Feature Configurations ---\n",
    "polygnn_atom_config = AtomConfig(\n",
    "    element_type=True, degree=True, implicit_valence=True, formal_charge=True,\n",
    "    num_rad_e=True, hybridization=True, aromatic=True, chirality=True, combo_hybrid=False # combo_hybrid=False here\n",
    ")\n",
    "polygnn_bond_config = BondConfig(bond_type=True, conjugation=True, ring=True)\n",
    "\n",
    "# ATOM_F_DIM is calculated based on AtomConfig.__post_init__\n",
    "ATOM_F_DIM = polygnn_atom_config.n_features\n",
    "EDGE_F_DIM = polygnn_bond_config.n_features\n",
    "print(f\"PolyGNN Atom feature dimension: {ATOM_F_DIM}\")\n",
    "print(f\"PolyGNN Bond feature dimension: {EDGE_F_DIM}\")\n",
    "\n",
    "pubchem_fp_calculator = PubChemFingerprint(count=False, sparse=False)\n",
    "temp_mol = Chem.MolFromSmiles('C')\n",
    "\n",
    "def mixfp(mol):\n",
    "    fp = []\n",
    "    fp_maccs = AllChem.GetMACCSKeysFingerprint(mol)\n",
    "    fp_pubcfp = pubchem_fp_calculator.transform([mol])[0]\n",
    "    fp.extend(fp_maccs.ToList())\n",
    "    fp.extend(fp_pubcfp)\n",
    "    return fp\n",
    "\n",
    "MIXFP_F_DIM = len(mixfp(temp_mol))\n",
    "print(f\"MixFP fingerprint dimension: {MIXFP_F_DIM}\")\n",
    "\n",
    "def smiles_to_pyg_data(smiles, atom_config=polygnn_atom_config, bond_config=polygnn_bond_config):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None: return None\n",
    "\n",
    "    atom_features_list = [atom_fp(atom, atom_config) for atom in mol.GetAtoms()]\n",
    "\n",
    "    x = torch.tensor(atom_features_list, dtype=torch.float)\n",
    "\n",
    "    edge_indices, edge_features_list = [], []\n",
    "    if mol.GetNumBonds() > 0:\n",
    "        for bond in mol.GetBonds():\n",
    "            i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "            edge_indices.extend([(i, j), (j, i)])\n",
    "            bond_feature = bond_fp(bond, bond_config)\n",
    "            edge_features_list.extend([bond_feature, bond_feature])\n",
    "        edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_features_list, dtype=torch.float)\n",
    "    else:\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "        edge_attr = torch.empty((0, EDGE_F_DIM), dtype=torch.float)\n",
    "\n",
    "    mixfp_features = mixfp(mol)\n",
    "    mixfp_vec = torch.tensor(mixfp_features, dtype=torch.float)\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr,\n",
    "                mixfp=mixfp_vec.unsqueeze(0), smiles=smiles)\n",
    "    return data\n",
    "\n",
    "class MultiTaskMoleculeDataset(Dataset):\n",
    "    def __init__(self, dataframe, smiles_data_map, prop_map):\n",
    "        super().__init__()\n",
    "        self.dataframe = dataframe\n",
    "        self.smiles_data_map = smiles_data_map\n",
    "        self.prop_map = prop_map\n",
    "        self.prop_selector_dim = len(prop_map)\n",
    "\n",
    "        self.selectors = np.stack(self.dataframe[PROP_COL].apply(lambda p: np.eye(self.prop_selector_dim)[self.prop_map[p]]).values).astype(np.float32)\n",
    "        self.targets_scaled = np.array(self.dataframe['scaled_value'].values, dtype=np.float32).reshape(-1, 1)\n",
    "        self.smiles_list = self.dataframe[SMILES_COL].values\n",
    "\n",
    "    def len(self): return len(self.dataframe)\n",
    "\n",
    "    def get(self, idx):\n",
    "        smiles = self.smiles_list[idx]\n",
    "        data_obj = self.smiles_data_map[smiles]\n",
    "        selector = torch.from_numpy(self.selectors[idx])\n",
    "        target_scaled = torch.from_numpy(self.targets_scaled[idx])\n",
    "        return data_obj, selector, target_scaled\n",
    "\n",
    "class CrossModalInteraction(nn.Module):\n",
    "    def __init__(self, gnn_dim, fp_dim, hidden_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.mlp_fp_to_gnn = nn.Sequential(nn.Linear(fp_dim, hidden_dim), nn.ReLU(), Dropout(dropout), nn.Linear(hidden_dim, gnn_dim))\n",
    "        self.mlp_gnn_to_fp = nn.Sequential(nn.Linear(gnn_dim, hidden_dim), nn.ReLU(), Dropout(dropout), nn.Linear(hidden_dim, fp_dim))\n",
    "        self.gate_activation = nn.Sigmoid()\n",
    "    def forward(self, gnn_embedding, fp_embedding):\n",
    "        refined_gnn, refined_fp = gnn_embedding, fp_embedding\n",
    "        embeddings_to_concat = []\n",
    "        if gnn_embedding is not None: embeddings_to_concat.append(gnn_embedding)\n",
    "        if fp_embedding is not None: embeddings_to_concat.append(fp_embedding)\n",
    "\n",
    "        if gnn_embedding is not None and fp_embedding is not None:\n",
    "            gnn_context = self.mlp_fp_to_gnn(fp_embedding); gnn_gate = self.gate_activation(gnn_context); refined_gnn = gnn_embedding * gnn_gate\n",
    "            fp_context = self.mlp_gnn_to_fp(gnn_embedding); fp_gate = self.gate_activation(fp_context); refined_fp = fp_embedding * fp_gate\n",
    "            embeddings_to_concat = [refined_gnn, refined_fp]\n",
    "\n",
    "        fused_vector = embeddings_to_concat[0] if len(embeddings_to_concat)==1 else torch.cat(embeddings_to_concat, dim=-1) if len(embeddings_to_concat) > 1 else None\n",
    "        return fused_vector, (None, None) # Gates not needed for standard forward\n",
    "\n",
    "class MultiTaskPredictor(nn.Module):\n",
    "    def __init__(self, node_feature_dim, mixfp_feature_dim, prop_selector_dim, gnn_hidden_dim, gnn_layers, fp_hidden_dim, fp_layers, interaction_hidden_dim, fusion_hidden_dim, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.dropout_rate = dropout; self.node_feature_dim = node_feature_dim; self.mixfp_feature_dim = mixfp_feature_dim; self.prop_selector_dim = prop_selector_dim\n",
    "        self.gnn_readout_dim, self.final_fp_dim = 0, 0\n",
    "        self.gnn_input_mlp, self.gine_convs, self.gnn_batch_norms = None, nn.ModuleList(), nn.ModuleList()\n",
    "        if node_feature_dim > 0 and gnn_layers > 0:\n",
    "            self.gnn_input_mlp = Linear(node_feature_dim, gnn_hidden_dim)\n",
    "            for _ in range(gnn_layers):\n",
    "                mlp = Sequential(Linear(gnn_hidden_dim, gnn_hidden_dim * 2), BatchNorm1d(gnn_hidden_dim * 2), ReLU(), Linear(gnn_hidden_dim * 2, gnn_hidden_dim))\n",
    "                self.gine_convs.append(GINEConv(nn=mlp, edge_dim=EDGE_F_DIM))\n",
    "                self.gnn_batch_norms.append(BatchNorm1d(gnn_hidden_dim))\n",
    "            self.gnn_readout_dim = gnn_hidden_dim * 2 # Global Add + Global Max\n",
    "        self.fp_layers_list, self.fp_batch_norms = nn.ModuleList(), nn.ModuleList()\n",
    "        if mixfp_feature_dim > 0:\n",
    "            if fp_layers > 0:\n",
    "                self.fp_layers_list.append(Linear(mixfp_feature_dim, fp_hidden_dim)); self.fp_batch_norms.append(BatchNorm1d(fp_hidden_dim))\n",
    "                for _ in range(fp_layers - 1): self.fp_layers_list.append(Linear(fp_hidden_dim, fp_hidden_dim)); self.fp_batch_norms.append(BatchNorm1d(fp_hidden_dim))\n",
    "                self.final_fp_dim = fp_hidden_dim\n",
    "            else: self.final_fp_dim = mixfp_feature_dim\n",
    "        self.interaction_module = None;\n",
    "        fusion_base_dim = 0\n",
    "        if self.gnn_readout_dim > 0 and self.final_fp_dim > 0 and interaction_hidden_dim > 0:\n",
    "             self.interaction_module = CrossModalInteraction(self.gnn_readout_dim, self.final_fp_dim, interaction_hidden_dim, dropout)\n",
    "             fusion_base_dim = self.gnn_readout_dim + self.final_fp_dim\n",
    "        elif self.gnn_readout_dim > 0: fusion_base_dim = self.gnn_readout_dim\n",
    "        elif self.final_fp_dim > 0: fusion_base_dim = self.final_fp_dim\n",
    "\n",
    "        fusion_input_dim = fusion_base_dim + prop_selector_dim\n",
    "\n",
    "        self.fusion_mlp = Sequential(Linear(fusion_input_dim, fusion_hidden_dim), ReLU(), BatchNorm1d(fusion_hidden_dim), Dropout(dropout),\n",
    "                                   Linear(fusion_hidden_dim, fusion_hidden_dim // 2), ReLU(), Dropout(dropout), Linear(fusion_hidden_dim // 2, 1))\n",
    "\n",
    "    def forward(self, data, selector):\n",
    "        x, edge_index, edge_attr, batch, mixfp = data.x, data.edge_index, data.edge_attr, data.batch, data.mixfp\n",
    "        graph_embedding, fp_embedding = None, None\n",
    "\n",
    "        if self.gnn_input_mlp is not None:\n",
    "            gnn_x = self.gnn_input_mlp(x)\n",
    "            for i in range(len(self.gine_convs)):\n",
    "                gnn_x = self.gine_convs[i](gnn_x, edge_index, edge_attr=edge_attr); bn = self.gnn_batch_norms[i]\n",
    "                gnn_x = F.relu(bn(gnn_x)); gnn_x = F.dropout(gnn_x, p=self.dropout_rate, training=self.training)\n",
    "            graph_embedding = torch.cat([global_add_pool(gnn_x, batch), global_max_pool(gnn_x, batch)], dim=-1)\n",
    "\n",
    "        if self.final_fp_dim > 0:\n",
    "             fp = mixfp.squeeze(1)\n",
    "             if len(self.fp_layers_list) > 0:\n",
    "                 for i in range(len(self.fp_layers_list)): bn_fp = self.fp_batch_norms[i]; fp = F.relu(bn_fp(self.fp_layers_list[i](fp))); fp = F.dropout(fp, p=self.dropout_rate, training=self.training)\n",
    "             fp_embedding = fp\n",
    "\n",
    "        fused_vector = None\n",
    "        if self.interaction_module is not None: fused_vector, _ = self.interaction_module(graph_embedding, fp_embedding)\n",
    "        else:\n",
    "            embeddings_to_use = []\n",
    "            if graph_embedding is not None: embeddings_to_use.append(graph_embedding)\n",
    "            if fp_embedding is not None: embeddings_to_use.append(fp_embedding)\n",
    "            fused_vector = embeddings_to_use[0] if len(embeddings_to_use) == 1 else torch.cat(embeddings_to_use, dim=-1) if len(embeddings_to_use) > 1 else None\n",
    "\n",
    "        if fused_vector is not None:\n",
    "             final_input = torch.cat([fused_vector, selector], dim=-1)\n",
    "        else:\n",
    "             final_input = selector\n",
    "\n",
    "        output = self.fusion_mlp(final_input)\n",
    "        return output\n",
    "\n",
    "def train_epoch(model, loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    num_samples = 0\n",
    "    for data_batch, selector_batch, target_batch in loader:\n",
    "        data_batch = data_batch.to(device)\n",
    "        selector_batch = selector_batch.to(device)\n",
    "        target_batch = target_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data_batch, selector_batch)\n",
    "        loss = loss_fn(out, target_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data_batch.num_graphs\n",
    "        num_samples += data_batch.num_graphs\n",
    "    return total_loss / num_samples\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, loss_fn, device, scalers, prop_names):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds_scaled, all_targets_scaled, all_props = [], [], []\n",
    "\n",
    "    for data_batch, selector_batch, target_batch in loader:\n",
    "        data_batch = data_batch.to(device)\n",
    "        selector_batch = selector_batch.to(device)\n",
    "        target_batch = target_batch.to(device)\n",
    "\n",
    "        out_scaled = model(data_batch, selector_batch)\n",
    "\n",
    "        total_loss += loss_fn(out_scaled, target_batch).item() * data_batch.num_graphs\n",
    "\n",
    "        all_preds_scaled.append(out_scaled.cpu().numpy())\n",
    "        all_targets_scaled.append(target_batch.cpu().numpy())\n",
    "\n",
    "        prop_indices = torch.argmax(selector_batch.cpu(), dim=1).numpy()\n",
    "        batch_props = [prop_names[i] for i in prop_indices]\n",
    "        all_props.extend(batch_props)\n",
    "\n",
    "    avg_loss_scaled = total_loss / sum(len(batch) for batch in all_preds_scaled)\n",
    "\n",
    "    preds_scaled_np = np.concatenate(all_preds_scaled, axis=0)\n",
    "    targets_scaled_np = np.concatenate(all_targets_scaled, axis=0)\n",
    "\n",
    "    metrics = {}\n",
    "    preds_orig_dict = {}\n",
    "    targets_orig_dict = {}\n",
    "\n",
    "    for prop_idx, prop in enumerate(prop_names):\n",
    "        prop_mask = np.array(all_props) == prop\n",
    "        if np.sum(prop_mask) > 0:\n",
    "            prop_preds_scaled = preds_scaled_np[prop_mask]\n",
    "            prop_targets_scaled = targets_scaled_np[prop_mask]\n",
    "\n",
    "            # --- FIX: Access scaler by index from the list ---\n",
    "            scaler = scalers[prop_idx]\n",
    "\n",
    "            if scaler is not None and hasattr(scaler, 'scale_') and scaler.scale_ is not None:\n",
    "                 prop_preds_orig = scaler.inverse_transform(prop_preds_scaled)\n",
    "                 prop_targets_orig = scaler.inverse_transform(prop_targets_scaled)\n",
    "\n",
    "                 preds_orig_dict[prop] = prop_preds_orig.flatten().tolist()\n",
    "                 targets_orig_dict[prop] = prop_targets_orig.flatten().tolist()\n",
    "\n",
    "                 mae_orig = mean_absolute_error(prop_targets_orig, prop_preds_orig)\n",
    "                 rmse_orig = np.sqrt(mean_squared_error(prop_targets_orig, prop_preds_orig))\n",
    "                 r2 = r2_score(prop_targets_orig, prop_preds_orig)\n",
    "                 metrics[prop] = {'MAE': mae_orig, 'RMSE': rmse_orig, 'R2': r2, 'count': int(np.sum(prop_mask))}\n",
    "            else:\n",
    "                 metrics[prop] = {'MAE': np.nan, 'RMSE': np.nan, 'R2': np.nan, 'count': int(np.sum(prop_mask))}\n",
    "        else:\n",
    "             metrics[prop] = {'MAE': np.nan, 'RMSE': np.nan, 'R2': np.nan, 'count': 0}\n",
    "             preds_orig_dict[prop] = []\n",
    "             targets_orig_dict[prop] = []\n",
    "\n",
    "\n",
    "    return avg_loss_scaled, metrics, targets_orig_dict, preds_orig_dict\n",
    "\n",
    "# --- Data Loading and Preparation ---\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df.dropna(subset=[SMILES_COL, VALUE_COL, PROP_COL], inplace=True)\n",
    "print(f\"Data loaded and cleaned, shape: {df.shape}\")\n",
    "\n",
    "TARGET_COLS = sorted(df[PROP_COL].unique().tolist())\n",
    "PROP_MAP = {prop: i for i, prop in enumerate(TARGET_COLS)}\n",
    "NUM_TASKS = len(TARGET_COLS)\n",
    "PROP_SELECTOR_DIM = NUM_TASKS\n",
    "print(f\"Detected target properties: {TARGET_COLS}\")\n",
    "print(f\"Number of tasks (properties): {NUM_TASKS}\")\n",
    "\n",
    "print(\"\\nPre-generating PyG Data objects for unique SMILES...\")\n",
    "unique_smiles = df[SMILES_COL].unique().tolist()\n",
    "smiles_data_map = {}\n",
    "pregenerated_data_path = os.path.join(BEST_MODEL_SAVE_DIR, PREGENERATED_DATA_FILE)\n",
    "\n",
    "if os.path.exists(pregenerated_data_path):\n",
    "    print(f\"Loading pre-generated data from {pregenerated_data_path}\")\n",
    "    smiles_data_map = joblib.load(pregenerated_data_path)\n",
    "    smiles_data_map = {s: d for s, d in smiles_data_map.items() if d is not None}\n",
    "    print(f\"Loaded data for {len(smiles_data_map)} unique SMILES.\")\n",
    "else:\n",
    "    print(\"Pre-generated data not found. Generating...\")\n",
    "    for smiles in tqdm(unique_smiles, desc=\"Generating Data objects\"):\n",
    "        data_obj = smiles_to_pyg_data(smiles)\n",
    "        if data_obj is not None:\n",
    "            smiles_data_map[smiles] = data_obj\n",
    "\n",
    "    print(f\"Generated data for {len(smiles_data_map)} unique SMILES.\")\n",
    "    print(f\"Saving pre-generated data to {pregenerated_data_path}\")\n",
    "    joblib.dump(smiles_data_map, pregenerated_data_path)\n",
    "\n",
    "df = df[df[SMILES_COL].isin(smiles_data_map.keys())].reset_index(drop=True)\n",
    "print(f\"Filtered dataframe based on successful data generation, shape: {df.shape}\")\n",
    "\n",
    "print(\"\\nSplitting data (stratified by property)...\")\n",
    "train_val_df, test_df = train_test_split(df, test_size=TEST_SPLIT_RATIO, stratify=df[PROP_COL], random_state=RANDOM_STATE)\n",
    "\n",
    "train_val_df = train_val_df.copy().reset_index(drop=True)\n",
    "test_df = test_df.copy().reset_index(drop=True)\n",
    "\n",
    "print(f\"Train/Val set size: {len(train_val_df)}, Test set size: {len(test_df)}\")\n",
    "print(\"Train/Val property distribution:\\n\", train_val_df[PROP_COL].value_counts(normalize=True).sort_index())\n",
    "print(\"Test property distribution:\\n\", test_df[PROP_COL].value_counts(normalize=True).sort_index())\n",
    "\n",
    "print(\"\\nFitting main scalers (MinMaxScaler) per property...\")\n",
    "main_scalers = [] # Store scalers in a list\n",
    "for prop in TARGET_COLS:\n",
    "    scaler = MinMaxScaler()\n",
    "    prop_train_val_data = train_val_df[train_val_df[PROP_COL] == prop][VALUE_COL].values.reshape(-1, 1)\n",
    "    if len(prop_train_val_data) > 0:\n",
    "        scaler.fit(prop_train_val_data)\n",
    "    main_scalers.append(scaler)\n",
    "\n",
    "main_scalers_path = os.path.join(BEST_MODEL_SAVE_DIR, SCALERS_SAVE_FILE)\n",
    "target_cols_path = os.path.join(BEST_MODEL_SAVE_DIR, TARGET_COLS_FILE)\n",
    "joblib.dump(main_scalers, main_scalers_path)\n",
    "joblib.dump(TARGET_COLS, target_cols_path)\n",
    "print(f\"Main scalers and target columns saved to: {main_scalers_path}, {target_cols_path}\")\n",
    "\n",
    "print(f\"\\n--- Starting {N_FOLDS}-Fold Stratified CV ---\")\n",
    "kf_mtl = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=RANDOM_STATE + 1)\n",
    "\n",
    "fold_model_paths = []\n",
    "fold_best_hyperparams = []\n",
    "\n",
    "train_val_indices = train_val_df.index.tolist()\n",
    "train_val_stratify_target = train_val_df[PROP_COL]\n",
    "\n",
    "for fold, (fold_train_indices, fold_val_indices) in enumerate(kf_mtl.split(train_val_indices, train_val_stratify_target)):\n",
    "    print(f\"\\n===== Fold {fold + 1}/{N_FOLDS} =====\")\n",
    "    train_df_fold = train_val_df.iloc[fold_train_indices].copy().reset_index(drop=True)\n",
    "    val_df_fold = train_val_df.iloc[fold_val_indices].copy().reset_index(drop=True)\n",
    "\n",
    "    print(f\"Fold Train size: {len(train_df_fold)}, Fold Val size: {len(val_df_fold)}\")\n",
    "\n",
    "    print(f\"\\n--- Fold {fold + 1}: Fitting fold scalers per property ---\")\n",
    "    fold_scalers = [] \n",
    "    for prop in TARGET_COLS:\n",
    "        scaler = MinMaxScaler()\n",
    "        prop_train_data = train_df_fold[train_df_fold[PROP_COL] == prop][VALUE_COL].values.reshape(-1, 1)\n",
    "        if len(prop_train_data) > 0:\n",
    "            scaler.fit(prop_train_data)\n",
    "        fold_scalers.append(scaler)\n",
    "\n",
    "    train_df_fold['scaled_value'] = np.nan\n",
    "    val_df_fold['scaled_value'] = np.nan\n",
    "\n",
    "    for prop_idx, prop in enumerate(TARGET_COLS):\n",
    "         scaler = fold_scalers[prop_idx]\n",
    "         train_prop_mask = train_df_fold[PROP_COL] == prop\n",
    "         train_prop_data = train_df_fold.loc[train_prop_mask, VALUE_COL].values.reshape(-1, 1)\n",
    "         if hasattr(scaler, 'scale_') and scaler.scale_ is not None and len(train_prop_data) > 0:\n",
    "             train_df_fold.loc[train_prop_mask, 'scaled_value'] = scaler.transform(train_prop_data).flatten()\n",
    "\n",
    "         val_prop_mask = val_df_fold[PROP_COL] == prop\n",
    "         val_prop_data = val_df_fold.loc[val_prop_mask, VALUE_COL].values.reshape(-1, 1)\n",
    "         if hasattr(scaler, 'scale_') and scaler.scale_ is not None and len(val_prop_data) > 0:\n",
    "              val_df_fold.loc[val_prop_mask, 'scaled_value'] = scaler.transform(val_prop_data).flatten()\n",
    "\n",
    "\n",
    "    train_df_fold.dropna(subset=['scaled_value'], inplace=True)\n",
    "    val_df_fold.dropna(subset=['scaled_value'], inplace=True)\n",
    "    print(f\"Fold Train size after dropping unscalable samples: {len(train_df_fold)}\")\n",
    "    print(f\"Fold Val size after dropping unscalable samples: {len(val_df_fold)}\")\n",
    "\n",
    "\n",
    "    # --- Optuna Split (from train_df_fold) ---\n",
    "    print(f\"\\n--- Fold {fold + 1}: Running Optuna ---\")\n",
    "    if len(train_df_fold) == 0:\n",
    "        print(f\"  Fold {fold + 1}: No training data after scaling filtering. Skipping Optuna.\")\n",
    "        fold_best_hyperparams.append({})\n",
    "        continue\n",
    "\n",
    "    optuna_train_df, optuna_val_df = train_test_split(train_df_fold, test_size=VALIDATION_SPLIT_OPTUNA, stratify=train_df_fold[PROP_COL], random_state=RANDOM_STATE + fold + 2)\n",
    "\n",
    "    optuna_train_df = optuna_train_df.copy().reset_index(drop=True)\n",
    "    optuna_val_df = optuna_val_df.copy().reset_index(drop=True)\n",
    "\n",
    "    optuna_train_dataset = MultiTaskMoleculeDataset(optuna_train_df, smiles_data_map, PROP_MAP)\n",
    "    optuna_val_dataset = MultiTaskMoleculeDataset(optuna_val_df, smiles_data_map, PROP_MAP)\n",
    "\n",
    "    def objective(trial):\n",
    "         lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "         weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-4, log=True)\n",
    "         dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
    "         batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "         fusion_hidden_dim = trial.suggest_categorical(\"fusion_hidden_dim\", [64, 128, 256, 512])\n",
    "         gnn_hidden_dim, gnn_layers = (trial.suggest_categorical(\"gnn_hidden_dim\", [32, 64, 128, 256]), trial.suggest_int(\"gnn_layers\", 1, 5)) if ATOM_F_DIM > 0 else (0, 0)\n",
    "         fp_hidden_dim, fp_layers = (trial.suggest_categorical(\"fp_hidden_dim\", [128, 256, 512, 1024]), trial.suggest_int(\"fp_layers\", 1, 4)) if MIXFP_F_DIM > 0 else (0, 0)\n",
    "         interaction_hidden_dim = trial.suggest_categorical(\"interaction_hidden_dim\", [32, 64, 128]) if (gnn_layers > 0 and fp_layers >= 0) and (ATOM_F_DIM > 0 and MIXFP_F_DIM > 0) else 0\n",
    "\n",
    "\n",
    "         model = MultiTaskPredictor(\n",
    "             node_feature_dim=ATOM_F_DIM, mixfp_feature_dim=MIXFP_F_DIM, prop_selector_dim=PROP_SELECTOR_DIM,\n",
    "             gnn_hidden_dim=gnn_hidden_dim, gnn_layers=gnn_layers,\n",
    "             fp_hidden_dim=fp_hidden_dim, fp_layers=fp_layers,\n",
    "             interaction_hidden_dim=interaction_hidden_dim,\n",
    "             fusion_hidden_dim=fusion_hidden_dim,\n",
    "             dropout=dropout\n",
    "         ).to(device)\n",
    "\n",
    "         optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "         scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5)\n",
    "         loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "         train_drop_last_optuna = len(optuna_train_dataset) > 1 and len(optuna_train_dataset) % batch_size == 1\n",
    "         temp_train_loader = DataLoader(optuna_train_dataset, batch_size=batch_size, shuffle=True, drop_last=train_drop_last_optuna)\n",
    "\n",
    "         temp_val_loader = DataLoader(optuna_val_dataset, batch_size=256, shuffle=False) if len(optuna_val_dataset) > 0 else None\n",
    "\n",
    "         optuna_epochs, optuna_patience = 150, 15\n",
    "         best_optuna_val_loss, epochs_no_improve = float('inf'), 0\n",
    "\n",
    "         for epoch in range(1, optuna_epochs + 1):\n",
    "             train_loss_scaled = train_epoch(model, temp_train_loader, optimizer, loss_fn, device)\n",
    "             current_val_loss = float('inf')\n",
    "\n",
    "             if temp_val_loader is not None and len(temp_val_loader) > 0:\n",
    "                 val_loss_scaled, _, _, _ = evaluate(model, temp_val_loader, loss_fn, device, fold_scalers, TARGET_COLS)\n",
    "                 current_val_loss = val_loss_scaled\n",
    "\n",
    "                 scheduler.step(current_val_loss)\n",
    "\n",
    "                 if current_val_loss < best_optuna_val_loss:\n",
    "                     best_optuna_val_loss = current_val_loss; epochs_no_improve = 0\n",
    "                 else:\n",
    "                     epochs_no_improve += 1\n",
    "                     if epochs_no_improve >= optuna_patience: break\n",
    "             elif len(optuna_val_dataset) == 0:\n",
    "                  current_val_loss = train_loss_scaled\n",
    "                  best_optuna_val_loss = current_val_loss\n",
    "                  epochs_no_improve = 0\n",
    "\n",
    "             trial.report(current_val_loss, epoch)\n",
    "             if trial.should_prune(): raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "         return best_optuna_val_loss\n",
    "\n",
    "\n",
    "    start_time_optuna = time.time()\n",
    "    study = optuna.create_study(direction='minimize', pruner=optuna.pruners.MedianPruner())\n",
    "    study.optimize(objective, n_trials=N_TRIALS_OPTUNA, n_jobs=1)\n",
    "    end_time_optuna = time.time()\n",
    "    print(f\"Fold {fold + 1}: Optuna finished. Duration: {end_time_optuna - start_time_optuna:.2f} sec\")\n",
    "\n",
    "    current_fold_best_params = study.best_trial.params\n",
    "    if ATOM_F_DIM == 0 or current_fold_best_params.get('gnn_layers', 0) == 0: current_fold_best_params['gnn_hidden_dim'], current_fold_best_params['gnn_layers'] = 0, 0\n",
    "    if MIXFP_F_DIM == 0: current_fold_best_params['fp_hidden_dim'], current_fold_best_params['fp_layers'] = 0, 0\n",
    "    if not (ATOM_F_DIM > 0 and MIXFP_F_DIM > 0 and current_fold_best_params.get('gnn_layers', 0) > 0 and current_fold_best_params.get('fp_layers', -1) >= 0):\n",
    "         current_fold_best_params['interaction_hidden_dim'] = 0\n",
    "\n",
    "    fold_best_hyperparams.append(current_fold_best_params)\n",
    "    print(f\"Fold {fold + 1}: Optuna best hyperparameters:\\n {current_fold_best_params}\")\n",
    "    print(f\"Fold {fold + 1}: Best validation loss (Average MSE scaled): {study.best_trial.value:.6f}\")\n",
    "\n",
    "    # --- Final Fold Training ---\n",
    "    print(f\"\\n--- Fold {fold + 1}: Training final model ---\")\n",
    "\n",
    "    if len(train_df_fold) == 0:\n",
    "         print(f\"  Fold {fold + 1}: No training data available for final training. Skipping model save.\")\n",
    "         continue\n",
    "\n",
    "    train_dataset_fold = MultiTaskMoleculeDataset(train_df_fold, smiles_data_map, PROP_MAP)\n",
    "    val_dataset_fold = MultiTaskMoleculeDataset(val_df_fold, smiles_data_map, PROP_MAP)\n",
    "\n",
    "    fold_batch_size = current_fold_best_params.get('batch_size', 64)\n",
    "\n",
    "    train_drop_last_fold = len(train_dataset_fold) > 1 and len(train_dataset_fold) % fold_batch_size == 1\n",
    "    train_loader_fold = DataLoader(train_dataset_fold, batch_size=fold_batch_size, shuffle=True, drop_last=train_drop_last_fold)\n",
    "\n",
    "    val_loader_fold = DataLoader(val_dataset_fold, batch_size=256, shuffle=False) if len(val_dataset_fold) > 0 else None\n",
    "\n",
    "    final_model = MultiTaskPredictor(\n",
    "        node_feature_dim=ATOM_F_DIM, mixfp_feature_dim=MIXFP_F_DIM, prop_selector_dim=PROP_SELECTOR_DIM,\n",
    "        gnn_hidden_dim=current_fold_best_params['gnn_hidden_dim'],\n",
    "        gnn_layers=current_fold_best_params['gnn_layers'],\n",
    "        fp_hidden_dim=current_fold_best_params['fp_hidden_dim'],\n",
    "        fp_layers=current_fold_best_params['fp_layers'],\n",
    "        interaction_hidden_dim=current_fold_best_params['interaction_hidden_dim'],\n",
    "        fusion_hidden_dim=current_fold_best_params['fusion_hidden_dim'],\n",
    "        dropout=current_fold_best_params['dropout']\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer_final = torch.optim.Adam(final_model.parameters(), lr=current_fold_best_params['lr'], weight_decay=current_fold_best_params['weight_decay'])\n",
    "    scheduler_final = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_final, 'min', factor=0.5, patience=max(1, PATIENCE_FOLD_TRAINING // 2))\n",
    "    loss_fn_final = torch.nn.MSELoss()\n",
    "\n",
    "    fold_best_final_val_loss, fold_final_epochs_no_improve, best_epoch_fold = float('inf'), 0, 0\n",
    "    best_model_fold_state = None\n",
    "    train_start_time_fold = time.time()\n",
    "\n",
    "    for epoch in range(1, N_EPOCHS_FOLD_TRAINING + 1):\n",
    "        train_loss_scaled = train_epoch(final_model, train_loader_fold, optimizer_final, loss_fn_final, device)\n",
    "        epoch_summary_str = f\" F{fold + 1} E{epoch:03d}/{N_EPOCHS_FOLD_TRAINING} | Tr L(S): {train_loss_scaled:.5f}\"\n",
    "\n",
    "        if val_loader_fold is not None and len(val_loader_fold) > 0:\n",
    "            val_loss_scaled, val_metrics, _, _ = evaluate(final_model, val_loader_fold, loss_fn_final, device, fold_scalers, TARGET_COLS)\n",
    "            epoch_summary_str += f\" | V L(S): {val_loss_scaled:.5f}\"\n",
    "            if TARGET_COLS and len(val_metrics) > 0:\n",
    "                 first_prop = TARGET_COLS[0]\n",
    "                 if first_prop in val_metrics and 'MAE' in val_metrics[first_prop] and not np.isnan(val_metrics[first_prop]['MAE']):\n",
    "                     epoch_summary_str += f\" | V {first_prop} MAE: {val_metrics[first_prop]['MAE']:.4f}\"\n",
    "                 else:\n",
    "                      for prop in TARGET_COLS:\n",
    "                           if prop in val_metrics and val_metrics[prop]['count'] > 0 and not np.isnan(val_metrics[prop]['MAE']):\n",
    "                                epoch_summary_str += f\" | V {prop} MAE: {val_metrics[prop]['MAE']:.4f}\"\n",
    "                                break\n",
    "\n",
    "            scheduler_final.step(val_loss_scaled)\n",
    "            if val_loss_scaled < fold_best_final_val_loss:\n",
    "                 fold_best_final_val_loss = val_loss_scaled; fold_final_epochs_no_improve = 0; best_epoch_fold = epoch\n",
    "                 best_model_fold_state = copy.deepcopy(final_model.state_dict())\n",
    "            else:\n",
    "                 fold_final_epochs_no_improve += 1\n",
    "                 if fold_final_epochs_no_improve >= PATIENCE_FOLD_TRAINING:\n",
    "                     print(epoch_summary_str); print(f\"  Early stopping. Best Epoch: {best_epoch_fold}\"); break\n",
    "        else:\n",
    "             best_model_fold_state = copy.deepcopy(final_model.state_dict()); best_epoch_fold = epoch\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == N_EPOCHS_FOLD_TRAINING: print(epoch_summary_str)\n",
    "\n",
    "    train_end_time_fold = time.time()\n",
    "    print(f\"  Fold {fold + 1} training finished. Duration: {train_end_time_fold - train_start_time_fold:.2f} sec.\")\n",
    "\n",
    "    current_fold_model_path = os.path.join(BEST_MODEL_SAVE_DIR, f'model_fold_{fold + 1}_best.pth')\n",
    "    if best_model_fold_state is not None:\n",
    "        torch.save(best_model_fold_state, current_fold_model_path)\n",
    "        print(f\"  Fold {fold + 1} best model saved to: {current_fold_model_path} (from epoch {best_epoch_fold})\")\n",
    "        fold_model_paths.append(current_fold_model_path)\n",
    "    else:\n",
    "        print(f\"  Fold {fold + 1}: No model state saved, skipping model path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "093c49df-f7b0-472c-8270-43fd97ca090e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Test Set Evaluation ---\n",
      "Using 5 models for ensemble prediction on the test set.\n",
      "Main scalers and target columns loaded for test evaluation.\n",
      "\n",
      "Scaling test data using main scalers...\n",
      "Test size after scaling and filtering: 3284\n",
      "Test dataset size (from loader): 3284\n",
      "Loading models for ensemble...\n",
      "\n",
      "Starting ensemble prediction on test set (5 models)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test Prediction: 100%|█████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 20.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test Set Results (Original Scale) ---\n",
      "(Based on 3284 samples in test_loader)\n",
      "Ensemble prediction used 5 models.\n",
      "\n",
      "  Property: SP (N=141)\n",
      "    R² Score: 0.7708\n",
      "    MAE:      30.0630\n",
      "    RMSE:     44.9146\n",
      "--------------------\n",
      "  Property: Tc (N=85)\n",
      "    R² Score: 0.7970\n",
      "    MAE:      31.1843\n",
      "    RMSE:     40.2944\n",
      "--------------------\n",
      "  Property: Td (N=1024)\n",
      "    R² Score: 0.8519\n",
      "    MAE:      26.1224\n",
      "    RMSE:     38.4488\n",
      "--------------------\n",
      "  Property: Tg (N=1452)\n",
      "    R² Score: 0.9347\n",
      "    MAE:      19.4773\n",
      "    RMSE:     27.7733\n",
      "--------------------\n",
      "  Property: Tm (N=582)\n",
      "    R² Score: 0.8713\n",
      "    MAE:      24.5684\n",
      "    RMSE:     34.4425\n",
      "--------------------\n",
      "Hyperparameters saved to: ./best_models_gine_mixfp_multitask_v3\\fold_best_hyperparams_multitask.joblib\n",
      "\n",
      "Script execution finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Test Set Evaluation ---\n",
    "print(\"\\n\\n--- Test Set Evaluation ---\")\n",
    "num_valid_models = len(fold_model_paths)\n",
    "if num_valid_models == 0:\n",
    "    print(\"No valid models saved from CV folds. Cannot perform test set evaluation.\")\n",
    "else:\n",
    "    print(f\"Using {num_valid_models} models for ensemble prediction on the test set.\")\n",
    "\n",
    "    main_scalers_loaded = joblib.load(os.path.join(BEST_MODEL_SAVE_DIR, SCALERS_SAVE_FILE))\n",
    "    loaded_target_cols = joblib.load(os.path.join(BEST_MODEL_SAVE_DIR, TARGET_COLS_FILE))\n",
    "    print(\"Main scalers and target columns loaded for test evaluation.\")\n",
    "\n",
    "    print(\"\\nScaling test data using main scalers...\")\n",
    "\n",
    "    test_df_scaled = test_df.copy() \n",
    "    test_df_scaled['scaled_value'] = np.nan\n",
    "\n",
    "    main_scalers_list = main_scalers_loaded \n",
    "    for prop_idx, prop in enumerate(loaded_target_cols):\n",
    "         scaler = main_scalers_list[prop_idx]\n",
    "         test_prop_mask = test_df_scaled[PROP_COL] == prop\n",
    "         test_prop_data = test_df_scaled.loc[test_prop_mask, VALUE_COL].values.reshape(-1, 1)\n",
    "\n",
    "         if hasattr(scaler, 'scale_') and scaler.scale_ is not None and len(test_prop_data) > 0:\n",
    "             test_df_scaled.loc[test_prop_mask, 'scaled_value'] = scaler.transform(test_prop_data).flatten()\n",
    "\n",
    "    test_df_scaled.dropna(subset=['scaled_value'], inplace=True) \n",
    "    print(f\"Test size after scaling and filtering: {len(test_df_scaled)}\")\n",
    "\n",
    "    if len(test_df_scaled) == 0:\n",
    "        print(\"No test data available after scaling. Skipping test set evaluation.\")\n",
    "    else:\n",
    "        test_dataset = MultiTaskMoleculeDataset(test_df_scaled, smiles_data_map, PROP_MAP)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "        print(f\"Test dataset size (from loader): {len(test_dataset)}\")\n",
    "\n",
    "        models = []\n",
    "        print(\"Loading models for ensemble...\")\n",
    "\n",
    "        loaded_fold_hps = {}\n",
    "        for saved_path in fold_model_paths:\n",
    "            try:\n",
    "                fold_num_str = os.path.basename(saved_path).split('_')[-2]\n",
    "                fold_num = int(fold_num_str)\n",
    "                if fold_num -1 >= 0 and fold_num - 1 < len(fold_best_hyperparams): \n",
    "                    loaded_fold_hps[fold_num] = fold_best_hyperparams[fold_num - 1]\n",
    "                else:\n",
    "                    print(f\"Warning: Hyperparameters for fold {fold_num} (path: {saved_path}) not found or index out of bounds. Skipping this model.\")\n",
    "            except (ValueError, IndexError) as e:\n",
    "                print(f\"Warning: Could not parse fold number from path {saved_path}: {e}. Skipping this model.\")\n",
    "\n",
    "\n",
    "        loaded_model_paths_filtered = []\n",
    "        for fold_num, hps in loaded_fold_hps.items():\n",
    "             model_path = os.path.join(BEST_MODEL_SAVE_DIR, f'model_fold_{fold_num}_best.pth')\n",
    "             if os.path.exists(model_path):\n",
    "                  gnn_hidden_dim = hps.get('gnn_hidden_dim', 0)\n",
    "                  gnn_layers = hps.get('gnn_layers', 0)\n",
    "                  fp_hidden_dim = hps.get('fp_hidden_dim', 0)\n",
    "                  fp_layers = hps.get('fp_layers', 0)\n",
    "                  interaction_hidden_dim = hps.get('interaction_hidden_dim', 0)\n",
    "                  fusion_hidden_dim = hps.get('fusion_hidden_dim', 128) \n",
    "                  dropout = hps.get('dropout', 0.3) \n",
    "\n",
    "                  if ATOM_F_DIM == 0 or gnn_layers == 0: gnn_hidden_dim, gnn_layers = 0,0\n",
    "                  if MIXFP_F_DIM == 0 or fp_layers == 0: fp_hidden_dim, fp_layers = 0,0 \n",
    "                  if not (ATOM_F_DIM > 0 and MIXFP_F_DIM > 0 and gnn_layers > 0 and fp_layers >=0):\n",
    "                       interaction_hidden_dim = 0\n",
    "\n",
    "                  model = MultiTaskPredictor(\n",
    "                      node_feature_dim=ATOM_F_DIM, mixfp_feature_dim=MIXFP_F_DIM, prop_selector_dim=PROP_SELECTOR_DIM,\n",
    "                      gnn_hidden_dim=gnn_hidden_dim, gnn_layers=gnn_layers,\n",
    "                      fp_hidden_dim=fp_hidden_dim, fp_layers=fp_layers,\n",
    "                      interaction_hidden_dim=interaction_hidden_dim,\n",
    "                      fusion_hidden_dim=fusion_hidden_dim,\n",
    "                      dropout=dropout\n",
    "                  ).to(device)\n",
    "                  try:\n",
    "                      model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "                      model.eval(); models.append(model)\n",
    "                      loaded_model_paths_filtered.append(model_path)\n",
    "                  except Exception as e:\n",
    "                      print(f\"Error loading state dict for model {model_path}: {e}. Skipping this model.\")\n",
    "             else:\n",
    "                 print(f\"Warning: Model path {model_path} does not exist. Skipping this model.\")\n",
    "\n",
    "\n",
    "        num_valid_models_after_load = len(models)\n",
    "        if num_valid_models_after_load == 0:\n",
    "            print(\"No models could be loaded. Cannot perform ensemble prediction.\")\n",
    "        else:\n",
    "            print(f\"\\nStarting ensemble prediction on test set ({num_valid_models_after_load} models)...\")\n",
    "            all_ensemble_preds_scaled = []\n",
    "            all_test_targets_scaled = [] \n",
    "            all_test_props = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for data_batch, selector_batch, target_batch_scaled in tqdm(test_loader, desc=\"Test Prediction\"): # MODIFIED: Renamed variable\n",
    "                    data_batch = data_batch.to(device)\n",
    "                    selector_batch = selector_batch.to(device)\n",
    "                    target_batch_scaled = target_batch_scaled.cpu()\n",
    "\n",
    "\n",
    "                    batch_preds_list_scaled = [model(data_batch, selector_batch) for model in models]\n",
    "                    stacked_preds_scaled = torch.stack(batch_preds_list_scaled)\n",
    "                    mean_preds_scaled = torch.mean(stacked_preds_scaled, dim=0)\n",
    "\n",
    "                    all_ensemble_preds_scaled.append(mean_preds_scaled.cpu().numpy())\n",
    "                    all_test_targets_scaled.append(target_batch_scaled.numpy()) \n",
    "\n",
    "                    prop_indices = torch.argmax(selector_batch.cpu(), dim=1).numpy()\n",
    "                    batch_props = [loaded_target_cols[i] for i in prop_indices]\n",
    "                    all_test_props.extend(batch_props)\n",
    "\n",
    "            final_ensemble_preds_scaled_np = np.concatenate(all_ensemble_preds_scaled, axis=0)\n",
    "            final_test_targets_scaled_np = np.concatenate(all_test_targets_scaled, axis=0) \n",
    "\n",
    "            test_metrics = {}\n",
    "            main_scalers_list = main_scalers_loaded \n",
    "\n",
    "            print(\"\\n--- Test Set Results (Original Scale) ---\")\n",
    "            print(f\"(Based on {len(test_dataset)} samples in test_loader)\")\n",
    "            print(f\"Ensemble prediction used {num_valid_models_after_load} models.\\n\")\n",
    "\n",
    "            for prop_idx, prop in enumerate(loaded_target_cols):\n",
    "                prop_mask = np.array(all_test_props) == prop\n",
    "                if np.sum(prop_mask) > 0:\n",
    "                    current_prop_preds_scaled = final_ensemble_preds_scaled_np[prop_mask]\n",
    "                    current_prop_targets_scaled = final_test_targets_scaled_np[prop_mask] \n",
    "\n",
    "                    scaler = main_scalers_list[prop_idx] \n",
    "\n",
    "                    if hasattr(scaler, 'scale_') and scaler.scale_ is not None and scaler.scale_ !=0 : \n",
    "                         prop_preds_orig = scaler.inverse_transform(current_prop_preds_scaled)\n",
    "                         prop_targets_orig = scaler.inverse_transform(current_prop_targets_scaled) \n",
    "\n",
    "                         mae_orig = mean_absolute_error(prop_targets_orig, prop_preds_orig)\n",
    "                         rmse_orig = np.sqrt(mean_squared_error(prop_targets_orig, prop_preds_orig))\n",
    "                         r2 = r2_score(prop_targets_orig, prop_preds_orig)\n",
    "                         test_metrics[prop] = {'MAE': mae_orig, 'RMSE': rmse_orig, 'R2': r2, 'count': int(np.sum(prop_mask))}\n",
    "                    else:\n",
    "                         print(f\"    Warning: Scaler for property '{prop}' is not properly fitted. Cannot compute original scale metrics.\")\n",
    "                         test_metrics[prop] = {'MAE': np.nan, 'RMSE': np.nan, 'R2': np.nan, 'count': int(np.sum(prop_mask))}\n",
    "                else:\n",
    "                     test_metrics[prop] = {'MAE': np.nan, 'RMSE': np.nan, 'R2': np.nan, 'count': 0}\n",
    "\n",
    "                # --- MODIFIED: Print results directly ---\n",
    "                metrics_prop = test_metrics.get(prop, {})\n",
    "                print(f\"  Property: {prop} (N={metrics_prop.get('count', 0)})\")\n",
    "                if metrics_prop.get('count', 0) > 0:\n",
    "                    print(f\"    R² Score: {metrics_prop.get('R2', float('nan')):.4f}\")\n",
    "                    print(f\"    MAE:      {metrics_prop.get('MAE', float('nan')):.4f}\")\n",
    "                    print(f\"    RMSE:     {metrics_prop.get('RMSE', float('nan')):.4f}\")\n",
    "                else:\n",
    "                    print(\"    No samples for this property in the test set.\")\n",
    "                print(\"-\" * 20)\n",
    "\n",
    "    HYPERPARAMS_SAVE_PATH = os.path.join(BEST_MODEL_SAVE_DIR, 'fold_best_hyperparams_multitask.joblib')\n",
    "    joblib.dump(fold_best_hyperparams, HYPERPARAMS_SAVE_PATH)\n",
    "    print(f\"Hyperparameters saved to: {HYPERPARAMS_SAVE_PATH}\")\n",
    "\n",
    "print(\"\\nScript execution finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43706f1a-7c9f-483a-b3dc-ec6e2d66e7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
